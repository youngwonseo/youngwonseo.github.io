<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width initial-scale=1">
  
  <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>딥러닝을 위한 고급도구#1 - 케라스 함수형 API | 서영원 블로그</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="딥러닝을 위한 고급도구#1 - 케라스 함수형 API" />
<meta name="author" content="Youngwon Seo" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="다중출력과 다중입력 모델" />
<meta property="og:description" content="다중출력과 다중입력 모델" />
<link rel="canonical" href="https://youngwonseo.github.io/07-01-keras/" />
<meta property="og:url" content="https://youngwonseo.github.io/07-01-keras/" />
<meta property="og:site_name" content="서영원 블로그" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-11-16T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="딥러닝을 위한 고급도구#1 - 케라스 함수형 API" />
<script type="application/ld+json">
{"url":"https://youngwonseo.github.io/07-01-keras/","author":{"@type":"Person","name":"Youngwon Seo"},"headline":"딥러닝을 위한 고급도구#1 - 케라스 함수형 API","dateModified":"2019-11-16T00:00:00+09:00","datePublished":"2019-11-16T00:00:00+09:00","description":"다중출력과 다중입력 모델","mainEntityOfPage":{"@type":"WebPage","@id":"https://youngwonseo.github.io/07-01-keras/"},"@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


  
  
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://youngwonseo.github.io/07-01-keras/">
  <link rel="alternate" type="application/atom+xml" title="서영원 블로그" href="https://youngwonseo.github.io/feed.xml" />  
  <link rel="stylesheet" href="/assets/css/syntax.css">
</head>

  <body>
    

<div class="header-container" id="header-container">

<!-- Site navigation -->
  <nav class="site-nav">
    <div class="trigger">
      
        
        <a class="page-link" href="/about/">About</a>
        
      
        
        <a class="page-link" href="/archive/">Archive</a>
        
      
        
      
        
      
        
      
        
        <a class="page-link" href="/category/">Paper</a>
        
      
        
        <a class="page-link" href="/projects/">Projects</a>
        
      
        
        <a class="page-link" href="/spring/">Spring</a>
        
      
        
        <a class="page-link" href="/study/">Study</a>
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
      <a class="page-link" href="/feed.xml">RSS</a>
    </div>
  </nav>

  <!-- The title of the site -->
  <header class="site-header">
    <!-- <a href="/">
      <div class="avatar">
        <img src="/assets/images/avatar.png" />
      </div>
    </a> -->
    <a class="site-title" href="/">서영원 블로그</a>
  </header>

</div>

      <div class="wrapper">
        <div class="page-content">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">딥러닝을 위한 고급도구#1 - 케라스 함수형 API</h1>
    <p class="post-meta">2019-11-16 / Youngwon Seo</p>
  </header>



  <article class="post-content">
    <h2 id="다중출력과-다중입력-모델">다중출력과 다중입력 모델</h2>

<p>지금까지 실습한 모델을 보면 모두 Sequential 모델을 사용하여 만들었습니다. Sequential 모델은 입력과 출력이 각각 하나라고 가정합니다. 하지만 경우에 따라 여러개의 입력이 사용되거나 여러개의 출력이 사용됩니다. 예를 들어 중고 의류 시장의 가격을 예측하는 모델을 생각해봅시다. 입력데이터로 의류의 메타데이터(의류 브랜드, 연도, 새상품가격 등), 설명글(의류 상태 등의 판매자가 작성한 글), 사진(의류 사진)을 입력으로 하면 메타데이터는 완전연결층, 설명글은 RNN, 사진은 CNN으로 처리할수가 있습니다.</p>

<p><img src="" alt="" /></p>

<p>간단하게는 각각을 전부 따로 사용하는 모델, 즉 각각의 입력이 가격을 예측하는 모델을 개발한 후 예측하는 가격의 평균을 사용하는 방법이지만 <strong>가능한 모든 종류의 입력 데이터를 동시에 사용해서 정확한 하나의 모델을 학습</strong>하는 것이 더 나은 방법입니다.</p>

<p>이와 비슷하게 입력은 하나이지만 출력이 여러개로 구분되는 모델도 존재할 수 있습니다.</p>

<p>최근 개발된 많은 신경망 구조는 이처럼 선형적이지 않은 네트워크 토폴로지(topology)가 필요합니다. 이에 대한 가장 대표적인 모델로 Inception 계열의 네트워크와 ResNet 계열의 네트워크 입니다. 다음의 그림을 살펴봅시다.</p>

<h4 id="inception">Inception</h4>
<p><img src="/public/keras/inception.png" alt="" /></p>

<h4 id="residual">Residual</h4>
<p><img src="/public/keras/residual.jpg" alt="" /></p>

<p>첫 번째 그림은 Inception 모듈을 의미합니다. 인셉션 모델은 인셉션 모듈들로 구성된 네트워크를 의미합니다. 인셉션 모듈을 살펴보면 입력이 여러개의 컨브넷으로 수행되고 다시 Concatenate됩니다. 
두 번째 그림은 Residual 모듈을 의미합니다. 하위층의 출력이 상위층의 출력이 더해지는 것을 볼 수 있습니다. 이 두가지 개념은 딥러닝 특히 CNN계열에서 아주 중요한 의미를 포함하고 있습니다. 뒤에서 코드와 함께 좀더 자세히 설명하겠습니다. 이 글에서의 핵심은 케라스의 함수형 API를 사용하면 위와 같은 다중출력 및 다중입력을 표현할 수 있다는 것입니다.</p>

<h2 id="케라스의-함수형-api">케라스의 함수형 API</h2>
<p>간단한 함수형 API예제를 살펴보겠습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">layers</span>

<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,))</span>
<span class="n">dense</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)</span>

<span class="n">output_tensor</span> <span class="o">=</span> <span class="n">dense</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
</code></pre></div></div>

<p>Input을 사용하여 입력을 만들고 dense에 Input을 입력하여 ouput을 만들어 내는 코드입니다. 다음은 Sequential과 함수형 API의 비교 코드입니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">Input</span>

<span class="c1">#Sequencetial 모델
</span><span class="n">seq_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">seq_model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,)))</span>
<span class="n">seq_model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">seq_model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>


<span class="c1">#함수형 API 모델
</span><span class="n">inpput_tensor</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">input_tensor</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">output_tensor</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">output_tensor</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>
<p>add로 연결하던 층들을 함수의 입출력을 사용하여 연결하고 있습니다. 한 가지 중요한 사항은 함수형 API에서 모델을 생성하는 단계에서 Model에 입력과 출력을 입력하는데 이때 <strong>입력과 출력은 연결</strong>되어 있어야 합니다. 연결되어 있지 않다면 RuntimeError를 발생시킵니다.</p>

<h3 id="다중입력모델">다중입력모델</h3>
<p>다중 입력모델을 만들때는 여러개의 입력 텐서들을 연결해야하는데 이를 위해 케라스의 keras.layers.add, keras.layers.concatenate 등을 사용합니다.</p>

<p><img src="/public/keras/multiple_input.png" alt="" /></p>

<p>예를 들어 질문-응답모델을 만든다고 생각해 봅시다. 입력은 질문과 답변이 존재하는 지문 출력은 응답이 있습니다. 입력이 두개이므로 다중입력 모델입니다. concatenate를 사용한 모델 코드를 살펴보겠습니다(Emdedding, LSTM등은 6장에서 살펴보았습니다).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">Input</span>

<span class="n">text_vocabulary_size</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">question_vocabulary_size</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">answer_vocabulary_size</span> <span class="o">=</span> <span class="mi">500</span>

<span class="c1">#첫 번째 입력
</span><span class="n">text_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'int32'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'text'</span><span class="p">)</span>
<span class="n">embedded_text</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">text_vocabulary_size</span><span class="p">,</span> <span class="mi">64</span><span class="p">)(</span><span class="n">text_input</span><span class="p">)</span>
<span class="n">encoded_text</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">32</span><span class="p">)(</span><span class="n">embedded_text</span><span class="p">)</span>

<span class="c1">#두 번째 입력
</span><span class="n">question_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'int32'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'question'</span><span class="p">)</span>
<span class="n">embedded_question</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">question_vocabulary_size</span><span class="p">,</span> <span class="mi">32</span><span class="p">)(</span><span class="n">question_input</span><span class="p">)</span>
<span class="n">encoded_question</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">16</span><span class="p">)(</span><span class="n">embedded_question</span><span class="p">)</span>

<span class="n">concatenated</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">encoded_text</span><span class="p">,</span> <span class="n">encoded_question</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># 두개의 텐서를 연결
</span>
<span class="n">answer</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">answer_vocabulary_size</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)(</span><span class="n">concatenated</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">([</span><span class="n">text_input</span><span class="p">,</span> <span class="n">question_input</span><span class="p">],</span> <span class="n">answer</span><span class="p">)</span> <span class="c1">#2개의 입력과 출력
</span><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'rmsprop'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">'categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'acc'</span><span class="p">])</span>
</code></pre></div></div>

<p>다음은 모델의 학습입니다. 입력과 출력데이터를 임의로 생성합니다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>

<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">max_length</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">text_vocabulary_size</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">max_length</span><span class="p">))</span>
<span class="n">question</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">question_vocabulary_size</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">max_length</span><span class="p">))</span>


<span class="n">answers</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">answer_vocabulary_size</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)</span>
<span class="n">answers</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">answers</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">([</span><span class="n">text</span><span class="p">,</span> <span class="n">question</span><span class="p">],</span> <span class="n">answers</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="c1">#model.fit({'text':text, 'question':question}, answers, epochs=10, batch_size=128)
#입력 텐서에 지정된 이름(name)을 통해 데이터 주입가능
</span></code></pre></div></div>
<p>fit을 통해 학습시킬때 데이터를 주입하는 방식이 두가지 존재합니다. 첫번째는 순서에 맞게 리스트로 구성하여 입력하는것과 모델구성시 입력에 지정된 이름을 통해 dict로 주입하는 방법입니다.</p>

<h3 id="다중출력모델">다중출력모델</h3>
<p>다중입력모델은 입력을 concatenate로 합치는 것이 특징입니다. 이와 다르게 다중출력모델은 출력이 여러개이므로 <strong>각 출력에 대한 loss가 지정</strong>되는것이 특징입니다. 입력이 상위계층으로 연결되면서 여러개의 층에 나눠서 들어가고 출력이 각각 결정되는것입니다. 다음은 소셜 미디어의 글을 가지고 작성자의 나이, 성별, 소득 수준을 예측하는 모델의 예제입니다.</p>

<p><img src="/public/keras/multiple_output.png" alt="" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">Input</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="n">vocabulary_size</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="n">num_income_groups</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">posts_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'int32'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'posts'</span><span class="p">)</span>
<span class="n">embedded_posts</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocabulary_size</span><span class="p">,</span> <span class="mi">256</span><span class="p">)(</span><span class="n">posts_input</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">embedded_posts</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling1D</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling1D</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">GlobalMaxPooling1D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="c1">#여기서 3개의 층으로 나누어짐
#출력1 - 나이
</span><span class="n">age_prediction</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'age'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span> 
<span class="c1">#출력2 - 소득
</span><span class="n">income_prediction</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_income_groups</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'income'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="c1">#출력1 - 성별
</span><span class="n">gender_prediction</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'gender'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">posts_input</span><span class="p">,</span> <span class="p">[</span><span class="n">age_prediction</span><span class="p">,</span> <span class="n">income_prediction</span><span class="p">,</span> <span class="n">gender_prediction</span><span class="p">])</span>

<span class="c1">#리스트 표현법
</span><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'rmsprop'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="p">[</span><span class="s">'mse'</span><span class="p">,</span> <span class="s">'categorical_crossentropy'</span><span class="p">,</span> <span class="s">'binary_crossentropy'</span><span class="p">])</span>
<span class="c1">#딕셔너리 표현법
</span><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'remsprop'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="p">{</span><span class="s">'age'</span><span class="p">:</span><span class="s">'mse'</span><span class="p">,</span> <span class="s">'income'</span><span class="p">:</span><span class="s">'categorical_crossentropy'</span><span class="p">,</span> <span class="s">'gender'</span><span class="p">:</span><span class="s">'binary_crossentropy'</span><span class="p">})</span>
</code></pre></div></div>

<p>각 출력은 다음과 같은 특징을 가집니다(소득의 경우 회귀(스칼라 예측)가 될 수 있지만 본 예제에서는 10개의 등급으로 나누었기 때문에 다중분류로 처리합니다).</p>
<ul>
  <li>나이 : 회귀</li>
  <li>소득 : 다중분류</li>
  <li>성별 : 이중분류</li>
</ul>

<p>그렇다면 손실을 가지고 학습을 진행하는 딥러닝은 여러개의 손실을 어떻게 사용해서 모델을 학습할까요? 가장 간단한 방법은 여러개의 손실을 모두 더하는 것입니다. 하지만 그렇게 학습할 경우 상대적으로 손실이 큰 항목을 위주로 학습일 될 것입니다. 이를 방지하기 위해 각 손실에 대한 기여도를 loss_weight으로 지정할 수 있습니다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#리스트 표현법
</span><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'rmsprop'</span><span class="p">,</span> 
              <span class="n">loss</span><span class="o">=</span><span class="p">[</span><span class="s">'mse'</span><span class="p">,</span> <span class="s">'categorical_crossentropy'</span><span class="p">,</span> <span class="s">'binary_crossentropy'</span><span class="p">],</span>
              <span class="n">loss_weight</span><span class="o">=</span><span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">])</span>
<span class="c1">#딕셔너리 표현법
</span><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'remsprop'</span><span class="p">,</span> 
              <span class="n">loss</span><span class="o">=</span><span class="p">{</span><span class="s">'age'</span><span class="p">:</span><span class="s">'mse'</span><span class="p">,</span> <span class="s">'income'</span><span class="p">:</span><span class="s">'categorical_crossentropy'</span><span class="p">,</span> <span class="s">'gender'</span><span class="p">:</span><span class="s">'binary_crossentropy'</span><span class="p">},</span>
              <span class="n">loss_weight</span><span class="o">=</span><span class="p">{</span><span class="s">'age'</span><span class="p">:</span><span class="mf">0.25</span><span class="p">,</span> <span class="s">'income'</span><span class="p">:</span><span class="mf">1.</span><span class="p">,</span> <span class="s">'gender'</span><span class="p">:</span><span class="mf">10.</span><span class="p">}</span>
            <span class="p">)</span>

</code></pre></div></div>
<p>나이의 경우 3~5의 오차(mse), 성별은 0.1정도의 오차(crossentorpy)가 존재한다고 할때 위와 같이 손실에 스케일링값을 주어 다중 출력 모델에서 전체의 loss를 조절할 수 있습니다.</p>

<p>다음은 위 모델의 학습에 대한 코드입니다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#리스트 표현법
</span><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">posts</span><span class="p">,</span> <span class="p">[</span><span class="n">age_targets</span><span class="p">,</span> <span class="n">income_targets</span><span class="p">,</span> <span class="n">gender_targets</span><span class="p">],</span>
          <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="c1">#딕셔너리 표현법
</span><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">posts</span><span class="p">,</span> <span class="p">{</span><span class="s">'age'</span><span class="p">:</span> <span class="n">age_targets</span><span class="p">,</span> <span class="s">'income'</span><span class="p">:</span> <span class="n">income_targets</span><span class="p">,</span> <span class="s">'gender'</span><span class="p">:</span> <span class="n">gender_targets</span><span class="p">],</span>
          <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="inception과-residual">Inception과 Residual</h3>
<p>위에서 잠시 언급했던 Inception과 Residual을 좀더 자세히 살펴봅시다.</p>

<p>함수형 API를 사용하면 다중 입/출력 모델 뿐만 아니라 비순환 유향 그래프(directed acyclic graph, DAG)를 만들 수 있습니다. 비순환이라는 것이 중요합니다. 이러한 구조중 가장 유명한 것이 Inception과 Residual입니다.</p>

<h4 id="inception-1">Inception</h4>
<p><img src="/public/keras/inception.png" alt="" />
Inception은 network in network 구조에 영감을 받아 구글에서 만든 CNN기반 모듈로 여러개의 CNN 구조를 거쳐 Concatenate를 통해 하나로 출력하는 모듈을 의미합니다. 1x1 합성곱과 3x3 합성곱등이 포함됩니다. 이런 구성(모듈안의 구성)은 네트워크가 따로따로 공간 특성과 채널 방향의 특성을 학습하도록 돕습니다. 종류에 따라 V1, V2, V3등의 모델로 구분(모듈을 구성하는 컨브넷의 사이즈, 개수 등이 차이)됩니다.</p>

<p>여기서 Inception의 직접적인 구현코드는 살펴보지 않겠습니다(책을 참조해주세요). 케라스API(keras.applications.inception_v3.InceptionV3)에는 Inception을 구현해놓고 ImageNet데이터로 학습한 모델을 지원합니다.</p>

<blockquote>
  <p>참조 논문 : Going Deeper with Convolutions(https://arxiv.org/abs/1409.4842)</p>
</blockquote>

<h4 id="resnet">ResNet</h4>
<p><img src="/public/keras/residual.jpg" alt="" />
Residual connection을 살펴보면 하위층의 출력을 상위층에 더하는 역활을 합니다. 이는 대규모 딥러닝 모델(층이 많은)에서 흔히 나타나는 두가지 문제인 그래디언트 소실(vanishing gradient)과 표현 병목(representational bottleneck)을 해결한 모델입니다. 일반적으로 10개 이상의 층을 가진 모델에 Residual connection을 추가하면 도움이 됩니다.</p>

<p>기본원리는 하위층의 출력이 상위층의 출력에 더해지는것입니다. 그래서 두층의 아웃풋의 텐서 크기가 동일해야 합니다. layers.add([y, redidual])과 같이 더하여 적용합니다.</p>

<blockquote>
  <p>참조 논문 : Deep Residual Learning for Image Recognition(https://arxiv.org/abs/1512.03385)</p>
</blockquote>

<h3 id="층-가중치-공유">층 가중치 공유</h3>
<p>함수형 API의 또 다른 특징은 하나의 층을 두번 호출하여 새로운 층을 생성하지 않고 같은 층의 가중치를 공유해서 사용하는 것입니다.</p>

<p>예를 들어 두 문장의 의미가 비슷한지 측정하는 모델을 가정해 봅시다. 이 모델은 두개의 문장을 입력으로 받고 0또는 1을 출력합니다(대화 시스템에서 중복 질문 제거 등에 유용하게 사용될 수 있습니다).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">Input</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>

<span class="n">lstm</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span> <span class="c1">#하나의 lstm
</span><span class="n">left_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>
<span class="n">left_output</span> <span class="o">=</span> <span class="n">lstm</span><span class="p">(</span><span class="n">left_input</span><span class="p">)</span>

<span class="n">right_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>
<span class="n">right_output</span> <span class="o">=</span> <span class="n">lstm</span><span class="p">(</span><span class="n">right_input</span><span class="p">)</span>

<span class="n">merged</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">left_output</span><span class="p">,</span> <span class="n">right_output</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">)(</span><span class="n">merged</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">([</span><span class="n">left_input</span><span class="p">,</span> <span class="n">right_input</span><span class="p">],</span> <span class="n">predictions</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">([</span><span class="n">left_data</span><span class="p">,</span> <span class="n">right_data</span><span class="p">],</span> <span class="n">targets</span><span class="p">)</span>

</code></pre></div></div>
<p>이 모델의 경우 A와 B나 B와 A의 입력의 출력이 같아야 합니다. 그래서 입력 A와 입력 B가 같은 lstm을 사용하고 있습니다. 두개의 입력에 대해 함께 학습되는 lstm으로 이를 샴 LSTM(siamese LSTM)모델 또는 공유 LSTM 이라고 부릅니다. 이처럼 함수형 API를 사용하면 모델에 따라 공유하는 층을 사용할 수 있습니다.</p>

<h3 id="모델과-층">모델과 층</h3>
<p>마지막으로 함수형 API를 사용하면 <strong>모델</strong>을 <strong>층</strong>처럼 사용할 수 있습니다.</p>

  </article>

  <hr>

  <!-- <div class="question">
    <h2>Questions?</h2>
    <p>Have a question regarding the post above? <br />Or any of my designs?</p>
    

  </div> -->

  <!-- <div class="related">
    <h2>Related</h2>
    
      <li><a href="/spring-guide/reactive-rest-service/" title="Building a Reactive RESTful Web Service">Building a Reactive RESTful Web Service
       &nbsp; <span class="post-meta">April 04, 2021</span></a>
    
      <li><a href="/projects/auction-market/" title="경매 서비스">경매 서비스
       &nbsp; <span class="post-meta">March 29, 2021</span></a>
    
      <li><a href="/kubernetes/ingress/" title="쿠버네티스 - 인그레스(Ingress)">쿠버네티스 - 인그레스(Ingress)
       &nbsp; <span class="post-meta">February 19, 2021</span></a>
    
  </div> -->

  
  
    <script src="https://utteranc.es/client.js"
      repo="youngwonseo/youngwonseo.github.io"
      issue-term="pathname"
      theme="github-light"
      crossorigin="anonymous"
      async>
    </script>
  

</div>

        </div>
        <footer class="site-footer">
<p class="small"></p>
</footer>

    </div>

    <script src="//cdn.jsdelivr.net/headroomjs/0.5.0/headroom.min.js"></script>
    <script type="text/javascript">
      var el = document.querySelector(".header-container");
      var headroom  = new Headroom(el, {
        "offset": 205,
        "tolerance": 5
      });
      headroom.init();
    </script>


    <!-- Twitter Shizzle -->
    <script type="text/javascript">
    window.twttr = (function (d, s, id) {
      var t, js, fjs = d.getElementsByTagName(s)[0];
      if (d.getElementById(id)) return;
      js = d.createElement(s); js.id = id;
      js.src= "https://platform.twitter.com/widgets.js";
      fjs.parentNode.insertBefore(js, fjs);
      return window.twttr || (t = { _e: [], ready: function (f) { t._e.push(f) } });
    }(document, "script", "twitter-wjs"));
    </script>

  </body>
</html>
