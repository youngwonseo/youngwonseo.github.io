<!DOCTYPE html>
<html>

  <head>
	<!-- Meta -->
	<meta charset="UTF-8"/>
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
	<meta name="generator" content="Jekyll">

	<title>머신러닝의 기본요소#1</title>
  <meta name="description" content="">

	<!-- CSS & fonts -->
  <link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,500" rel="stylesheet">
  <link rel="stylesheet" href="/css/main.css">

  <!-- Open Graph -->
  <meta property="og:title" content="머신러닝의 기본요소#1">
  <meta property="og:type" content: "website">
  <meta property="og:url" content= "https://thereviewindex.com/blog/2019/11/12/04-01-keras/">
  <meta property="og:description" content="">
  <meta property="og:locale" content= "en_US">
  <meta property="og:site_name" content="The Review Index">
  <meta property="og:image" content="https://thereviewindex.com/blog/">
  <meta property="og:image:url" content="https://thereviewindex.com/blog/">
  <meta property="og:image:secure_url" content="https://thereviewindex.com/blog/">
  <meta property="og:image:type" content="image/png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="1200">
  
  <!-- twitter card -->
  <meta property="twitter:card" content="summary">
  <meta property="twitter:title" content="머신러닝의 기본요소#1">
  <meta property="twitter:description" content="">
  <meta property="twitter:url" content= "https://thereviewindex.com/blog/2019/11/12/04-01-keras/">
  <meta property="twitter:image" content="https://thereviewindex.com/blog/">


	<!-- RSS -->
	<link href="/atom.xml" type="application/atom+xml" rel="alternate" title="ATOM Feed" />

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/png" href="img/favicon.png">


  <!-- Google Analytics -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  
  ga('create', 'UA-78263144-1', 'auto');
  ga('send', 'pageview');
  </script>
  <!-- End Google Analytics -->

</head>

  <body>
    
    <!-- Facebook Comments Script -->
    <div id="fb-root"></div>
      <script>(function(d, s, id) {
        var js, fjs = d.getElementsByTagName(s)[0];
        if (d.getElementById(id)) return;
        js = d.createElement(s); js.id = id;
        js.src = 'https://connect.facebook.net/en_GB/sdk.js#xfbml=1&version=v2.11&appId=288262758360783';
        fjs.parentNode.insertBefore(js, fjs);
      }(document, 'script', 'facebook-jssdk'));</script>
  
    <div id="wrap">
  	  	
  	  	<!-- Navigation -->
  	  	<nav id="nav">
	<div id="nav-list">
		<a href="/">Home</a>

		<!-- Nav pages -->
	  
	    
	  
	    
	  
	    
	      <a href="/about/" title="About">About</a>
	    
	  
	    
	      <a href="/archive/" title="Archive">Archive</a>
	    
	  
	    
	  
	    
	  
	    
	  
	    
	      <a href="/ml/" title="Machine Learning">Machine Learning</a>
	    
	  
	    
	      <a href="/projects/" title="Projects">Projects</a>
	    
	  
	    
	      <a href="/study/" title="Study">Study</a>
	    
	  
	    
	  
	    
	  
	    
	  
	    
	  
	    
	  
	    
	  
	    
	  
	    
	  
	    
	  
	    
	  
    
    <!-- Nav links -->
	  <!-- <a href="/">Blog</a> -->


	</div>
  
  <!-- Nav footer -->
	
	  <footer>
	
	<!-- Your custom nav footer here -->
	
</footer>
	

</nav>

      
      <!-- Icon menu -->
  	  <a id="nav-menu">
  	  	<div id="menu"></div>
  	  </a>
  
        <!-- Header -->
        
          <header id="header">

	<!-- Your custom header here -->
	<span class="f-left">  
		<a href="/">
			<h1>
				<span>Youngwon Seo</span>
			</h1>
		</a>
	</span>

	<span id="nav-links" class="absolute right bottom">
		<!-- Nav pages -->
		
			
		
			
		
			
				<a href="/about/" title="About">About</a>
			
		
			
				<a href="/archive/" title="Archive">Archive</a>
			
		
			
		
			
		
			
		
			
				<a href="/ml/" title="Machine Learning">Machine Learning</a>
			
		
			
				<a href="/projects/" title="Projects">Projects</a>
			
		
			
				<a href="/study/" title="Study">Study</a>
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		
		
		<!-- Nav links -->
		<!-- <a href="/">Blog</a> -->

	</span>
	
	<!-- Google Analytics -->
  <script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
		
		ga('create', 'UA-78263144-1', 'auto');
		ga('send', 'pageview');
		</script>
		<!-- End Google Analytics -->
</header>


        
  
      <!-- Main content -->
  	  <div id="container">
  		  
  		<main>
  
  			<article id="post-page">
  <div class="parent f-right">
    <!-- Twitter -->
    <a href="https://twitter.com/share?url=https://thereviewindex.com/blog/2019/11/12/04-01-keras/&amp;text=머신러닝의 기본요소#1&amp;hashtags=thereviewindex" target="_blank">
      <span class="social-icon">  
        <svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M21.967 11.8c.018 5.93-4.607 11.18-11.177 11.18-2.172 0-4.25-.62-6.047-1.76l-.268.422-.038.5.186.013.168.012c.3.02.44.032.6.046 2.06-.026 3.95-.686 5.49-1.86l1.12-.85-1.4-.048c-1.57-.055-2.92-1.08-3.36-2.51l-.48.146-.05.5c.22.03.48.05.75.08.48-.02.87-.07 1.25-.15l2.33-.49-2.32-.49c-1.68-.35-2.91-1.83-2.91-3.55 0-.05 0-.01-.01.03l-.49-.1-.25.44c.63.36 1.35.57 2.07.58l1.7.04L7.4 13c-.978-.662-1.59-1.79-1.618-3.047a4.08 4.08 0 0 1 .524-1.8l-.825.07a12.188 12.188 0 0 0 8.81 4.515l.59.033-.06-.59v-.02c-.05-.43-.06-.63-.06-.87a3.617 3.617 0 0 1 6.27-2.45l.2.21.28-.06c1.01-.22 1.94-.59 2.73-1.09l-.75-.56c-.1.36-.04.89.12 1.36.23.68.58 1.13 1.17.85l-.21-.45-.42-.27c-.52.8-1.17 1.48-1.92 2L22 11l.016.28c.013.2.014.35 0 .52v.04zm.998.038c.018-.22.017-.417 0-.66l-.498.034.284.41a8.183 8.183 0 0 0 2.2-2.267l.97-1.48-1.6.755c.17-.08.3-.02.34.03a.914.914 0 0 1-.13-.292c-.1-.297-.13-.64-.1-.766l.36-1.254-1.1.695c-.69.438-1.51.764-2.41.963l.48.15a4.574 4.574 0 0 0-3.38-1.484 4.616 4.616 0 0 0-4.61 4.613c0 .29.02.51.08.984l.01.02.5-.06.03-.5c-3.17-.18-6.1-1.7-8.08-4.15l-.48-.56-.36.64c-.39.69-.62 1.48-.65 2.28.04 1.61.81 3.04 2.06 3.88l.3-.92c-.55-.02-1.11-.17-1.6-.45l-.59-.34-.14.67c-.02.08-.02.16 0 .24-.01 2.12 1.55 4.01 3.69 4.46l.1-.49-.1-.49c-.33.07-.67.12-1.03.14-.18-.02-.43-.05-.64-.07l-.76-.09.23.73c.57 1.84 2.29 3.14 4.28 3.21l-.28-.89a8.252 8.252 0 0 1-4.85 1.66c-.12-.01-.26-.02-.56-.05l-.17-.01-.18-.01L2.53 21l1.694 1.07a12.233 12.233 0 0 0 6.58 1.917c7.156 0 12.2-5.73 12.18-12.18l-.002.04z"></path></svg>
      </span>
    </a>

    &nbsp;&nbsp;&nbsp;
    <!-- Facebook -->
    <a href="http://www.facebook.com/sharer.php?u=https://thereviewindex.com/blog/2019/11/12/04-01-keras/" target="_blank">
      <span class="social-icon">
        <svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M16.39 23.61v-5.808h1.846a.55.55 0 0 0 .546-.48l.36-2.797a.551.551 0 0 0-.547-.62H16.39V12.67c0-.67.12-.813.828-.813h1.474a.55.55 0 0 0 .55-.55V8.803a.55.55 0 0 0-.477-.545c-.436-.06-1.36-.116-2.22-.116-2.5 0-4.13 1.62-4.13 4.248v1.513H10.56a.551.551 0 0 0-.55.55v2.797c0 .304.248.55.55.55h1.855v5.76c-4.172-.96-7.215-4.7-7.215-9.1 0-5.17 4.17-9.36 9.31-9.36 5.14 0 9.31 4.19 9.31 9.36 0 4.48-3.155 8.27-7.43 9.15M14.51 4C8.76 4 4.1 8.684 4.1 14.46c0 5.162 3.75 9.523 8.778 10.32a.55.55 0 0 0 .637-.543v-6.985a.551.551 0 0 0-.55-.55H11.11v-1.697h1.855a.55.55 0 0 0 .55-.55v-2.063c0-2.02 1.136-3.148 3.03-3.148.567 0 1.156.027 1.597.06v1.453h-.924c-1.363 0-1.93.675-1.93 1.912v1.78c0 .3.247.55.55.55h2.132l-.218 1.69H15.84c-.305 0-.55.24-.55.55v7.02c0 .33.293.59.623.54 5.135-.7 9.007-5.11 9.007-10.36C24.92 8.68 20.26 4 14.51 4"></path></svg>
      </span> 
    </a>
  </div>
  
  <h2>머신러닝의 기본요소#1</h2>		
	<div class="by-line parent">
    <time datetime="2019-11-12T00:00:00+09:00"> <i>12 Nov 2019</i> </time>
    &nbsp;&nbsp; &middot; &nbsp;&nbsp;
    <span><i></i> </span>
  </div>
	<div class="content">

		<p>[케라스창시자에게 배우는 딥러닝]의 4장 내용을 정리한 것입니다.</p>

<p>앞까지의 내용을 통해 신경망을 사용하여 분류와 회귀에 대한 문제를 어떻게 해결하는지 경험하였습니다. 또한 머신러닝에서 아주 중요한 문제인 과대적합에 대해서도 경험하였습니다. 이번장부터는 앞까지의 내용을 좀더 확고한 개념으로 정립하고 모델 평가, 데이터 전처리, 특성공학, 과대적합 같은 개념을 포함한 <strong>머신러닝 문제를 해결하기 위한 7단계의 작업 흐름</strong>을 정리해보겠습니다.</p>

<h2 id="1-머신러닝의-4가지-분류">1. 머신러닝의 4가지 분류</h2>
<p>머신러닝에 대한 공부를 시작하다보면 처음 접하는 용어가 지도/비지도 학습입니다. 여기서는 머신러닝의 4가지 종류에 대해 집어봅니다.</p>

<h3 id="11-지도학습">1.1 지도학습</h3>
<p>이전의 이진 분류(영화 리뷰 분류), 다중 분류(뉴스 기사 분류), 회귀(주택 가격 예측)는 지도학습(supervised learning)에 속합니다. 데이터에서도 보았듯이 데이터(data, sample)를 데이터에 대한 타깃(target, label)으로 매핑하도록 학습하는 방법을 의미합니다(영화 리뷰에서는 리뷰문장이 데이터이고 긍/부정결과가 타깃이었습니다). 지도학습의 대부분은 분류(classification)와 회귀(regression)로 구성됩니다. 다음은 또 다른 지도학습으로 해결가능한 문제들입니다.</p>

<ul>
  <li>시퀀스 생성(sequence generation) : 사진등에 대해 설명을 하는 글(sentence)을 생성하는 문제, 글을 구성하는 단어(word)를 예측하는 문제</li>
  <li>구문 트리(syntax tree) 예측 : 문장이 주어지면 분해된 구문 트리를 예측</li>
  <li>문체 감지(object detection) : 사진이 주어지면 사진안에서 특정 물체를 탐지, 사진안의 자동차를 탐지 등의 문제</li>
  <li>이미지 분할(image segmentation) : object detection은 사진안의 물체를 네모 박스(bounding box)로 탐지하지만 분할(segmentation)은 픽셀단위로 그 모양 까지 정확하게 분류해내는 문제</li>
</ul>

<h3 id="12-비지도학습">1.2 비지도학습</h3>
<p>비지도학습(unsupervised learning)은 지도학습과 다르게 타겟이 없고 데이터만을 가지고 학습합니다. 데이터의 특성만 가지고 비슷한 데이터끼리 군집(clustering), 데이터 압축 및 차원 축소(dimensionality reduction) 등이 비지도 학습에 포합됩니다. 지도학습으로 학습전 데이터를 탐색할때 필수적으로 사용됩니다.</p>

<h3 id="13-자기-지도-학습">1.3 자기 지도 학습</h3>
<p>자기 지도 학습(self-supervised learning)은 지도학습의 특별한 경우이지만 별도의 볌주로 나눌만큼 충분히 다릅니다. 자기 지도 학습은 타겟값을 입력데이터로 부터 생성후 지도학습을 하는 것을 의미합니다. 오토인코더(autoencoder)가 자기 지도 학습의 대표적인 예로 입력데이터를 그대로 타켓으로 설정하는 신경망의 종류입니다.</p>

<h3 id="14-강화학습">1.4 강화학습</h3>
<p>강화학습(reinforcement learning)은 딥마인트(DeepMind)가 아타리 게임을 플레이하도록 학습하거나 바둑을 두는 알파고 같은 시스템을 개발하기 위해 사용된 알고리즘입니다. 강화학습은 에이전트(agent)가 환경(environment)에 대한 정보를 받아 어떻게 행동(action)했을때 최고의 보상(reward)을 환경으로 받을지를 스스로 학습합니다.</p>

<h2 id="2-머신러닝-모델-평가">2. 머신러닝 모델 평가</h2>
<p>머신러닝의 목표는 학습한 데이터가 아닌 처음 본 데이터에서 잘 작동하는 <strong>일반화된 모델</strong>을 얻는 것입니다. 즉 과대적합되지 않도록 모델을 학습시키는 것입니다. 여기서는 이를 위한 방법을 설명합니다.</p>

<h3 id="21-훈련-검증-테스트-세트">2.1 훈련, 검증, 테스트 세트</h3>
<p>모델이 과적합되지 않는다는 것은 주어진 데이터를 훈련, 검증, 테스트로 나누고 훈련데이터와 테스트데이터의 성능이 유사하게 또는 테스트데이터의 성능이 더 높게 나온다는 것을 의미합니다. 그렇다면 훈련과 테스트 데이터만 있으면 되는데 검증데이터가 존재하는 이유는 무엇일까요? 그것은 모델은 항상 튜닝(사용자가 입력하는 하이퍼파라미터(층수, 유닛개수, 학습률 등)를 변경하면서 모델의 성능을 높이는 작업) 되기 때문입니다. 모델을 튜닝하기 위해서는 훈련때 사용하지 않은 데이터로 모델이 평가되어야 하는데 이를 위해 테스트데이터가 사용되면 결국 테스트데이터에 과적합될 수 있습니다. 즉 이런식으로 모델의 성능을 올려도 그 성능은 테스트데이터에 과적합된 것이기 때문에 새로발생하는 데이터에 대해서는 성능을 보장할 수 없습니다!</p>

<p>정리해 보면 학습 데이터로 학습을 하고 검증 데이터로 평가한 후 성능에 따라 다시 모델을 튜닝합니다. 이후 다시 학습 데이터로 학습하고 검증세트로 평가하는 작업을 반복하다 마지막에 테스트데이터로 성능을 평가하는것이 정확한 평가입니다. 테스트 데이터는 모델을 결정하는 것에 아무런 영향을 미치지 않는 정말 성능 평가를 위한 데이터 셋입니다.</p>

<p>다음 학습, 검증, 테스트 데이터셋을 이용한 3가지 모델 평가 방법입니다.</p>

<h4 id="단순-홀드-아웃-검증">단순 홀드 아웃 검증</h4>
<p>단일 홀드 아웃 검증(hold-out validation)은 전체 데이터를 학습, 검증, 테스트 셋으로 나누고 학습데이터셋으로 학습, 검증데이터셋으로 검증 후 튜닝, 테스트로 성능을 평가하는 가장 기초적인 방법입니다. 자세한 설명은 코드와 주석으로 대체합니다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_validation_samples</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">validation_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="n">num_validaion_samples</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">num_validation_samples</span><span class="p">:]</span>

<span class="n">training_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:]</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
<span class="n">validation_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">validation_data</span><span class="p">)</span>



<span class="n">model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">[</span><span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">])</span>

<span class="n">test_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="k-겹-교차-검증">K-겹 교차 검증</h4>
<p>K-겹 교차 검증(K-fold cross-validation)은 학습 데이터(학습과 테스트로 나누어진 데이터에서 학습데이터를 의미)를 동일한 k개로 나누고 k-1개를 학습, 1개를 검증 데이터로 돌려 측정되는 성능의 평균을 가지고 모델을 평가하는 방법입니다. k개로 나누어진 각 세트는 모두 검증데이터를 한번씩 하기때문에 총 k번 학습과 평가가 이루어집니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">k</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">num_validation_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">validation_scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
  <span class="n">validation_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">num_validation_samples</span> <span class="o">*</span> <span class="n">fold</span><span class="p">:</span> <span class="n">num_validation_samples</span> <span class="o">*</span> <span class="p">(</span><span class="n">fold</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
  <span class="n">training_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="n">num_validation_samples</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="n">num_validation_samples</span> <span class="o">*</span> <span class="p">(</span><span class="n">fold</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):]</span>

  <span class="n">model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">()</span>
  <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
  <span class="n">validation_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluation</span><span class="p">(</span><span class="n">validation_data</span><span class="p">)</span>
  <span class="n">validation_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">validation_score</span><span class="p">)</span>

  <span class="n">validation_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">validation_scores</span><span class="p">)</span>

  <span class="n">model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">()</span>
  <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
  <span class="n">test_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="셔플링을-사용한-k-겹-교차-검증">셔플링을 사용한 k-겹 교차 검증</h4>
<p>셔플링(shuffling)을 사용한 k-겹 교차 검증(iterated K-fold cross-validation)은 비교적 가용 데이터가 적고 정확하게 모델을 평가하고자 할때 사용됩니다. 이 방법은 K-겹 교차 검증을 여러번 적용하되, K개의 분할로 나누기전 매번 무작위 섞고 K-겹 교차 검증을 수행합니다. 즉 반복할 수(P)와 K가 정해지면 P X K 번의 학습 및 평가가 이루어져야해서 비용이 높다고 할 수 있습니다.</p>

<h2 id="3-데이터-전처리-특성-공학-특성-학습">3. 데이터 전처리, 특성 공학, 특성 학습</h2>

<h3 id="31-데이터-전처리">3.1 데이터 전처리</h3>
<p>신경망을 학습할려면 주어진 데이터를 신경망 입력에 적합하게 변형해야 합니다.</p>
<h4 id="백터화">백터화</h4>
<p>신경망의 모든 입력은 부동 소수데이터(필요에 따라 정수)로 이루어진 텐서입니다. 사운드, 이미지, 동영상 등 어떤것이든 텐서로 변환해서 신경망을 학습해야 합니다. 이렇게 텐서로 변환하는 것을 데이터 백터화(data vectorization)이라고 합니다. 앞 예제에서 영화 리뷰가 숫자로 이루어진 백터라는 것을 확인할 수 있었는데 이것인 이미 백터화가 되어 있는 데이터이기 때문입니다(더 정확하게는 원-핫 인코딩까지 포함해서 백터화라고 말할 수 있습니다).</p>

<h4 id="정규화">정규화</h4>
<p>정규화(regularization)는 입력되는 값을 일정한 범주 맞추는 것을 의미합니다. 이미지의 경우 한 픽셀의 값의 범위가 0~255가 될 수 있는데 255로 나누어 0~1의 값을 가지도록 정규화 할 수 있습니다. 이렇게 정규화를 하는 이유는 입력데이터를 기반으로 신경망의 가중치가 학습되는데 입력값이 너무 크거나 불균형적이면 가중치가 비용함수가 최소화되게 수렴하는 것을 방해합니다(경사하강법에서 그래디언트가 커지기 때문입니다). 따라서 네트워크를 쉽게 학습시킬려면 다음과 같이 데이터를 정규화 시킵니다.</p>
<ul>
  <li>작은 값을 취합니다. 0~1이 적당합니다.</li>
  <li>균일해야 합니다. 모든 특정이 같은 값의 범위를 취해야 합니다.</li>
</ul>

<p>추가적으로 자주 사용되는 정규화 방법입니다.</p>
<ul>
  <li>특성별 평균이 0, 표준편차가 1로 정규화합니다.
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">-=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1">#평균이 0이 되는 작업
</span><span class="n">x</span> <span class="o">/=</span> <span class="n">x</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># 표준편차가 1이 되는 작업
</span></code></pre></div>    </div>
    <p><strong>훈련세트에 사용된 정규화 방법은 테스트세트에서도 동일하게 이루어져야합니다.</strong></p>
  </li>
</ul>

<h4 id="누락된-값-다루기">누락된 값 다루기</h4>
<p>보통 NaN, Null로 처리되는 값으로 측정이 되지 않은 값을 의미합니다. 보통은 0으로 처리하거나 해당 데이터를 전체 데이터 세트에서 제거하고 진행합니다(0으로 취한할 경우는 취한되는 특성에 0값이 의미가 없어야 합니다).</p>

<h3 id="32-특성-공학">3.2 특성 공학</h3>

<h3 id="33-특성-학습">3.3 특성 학습</h3>


		
  </div>

  <div class="parent f-right">
    <!-- Twitter -->
    <a href="https://twitter.com/share?url=https://thereviewindex.com/blog/2019/11/12/04-01-keras/&amp;text=머신러닝의 기본요소#1&amp;hashtags=thereviewindex" target="_blank">
      <span class="social-icon">  
        <svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M21.967 11.8c.018 5.93-4.607 11.18-11.177 11.18-2.172 0-4.25-.62-6.047-1.76l-.268.422-.038.5.186.013.168.012c.3.02.44.032.6.046 2.06-.026 3.95-.686 5.49-1.86l1.12-.85-1.4-.048c-1.57-.055-2.92-1.08-3.36-2.51l-.48.146-.05.5c.22.03.48.05.75.08.48-.02.87-.07 1.25-.15l2.33-.49-2.32-.49c-1.68-.35-2.91-1.83-2.91-3.55 0-.05 0-.01-.01.03l-.49-.1-.25.44c.63.36 1.35.57 2.07.58l1.7.04L7.4 13c-.978-.662-1.59-1.79-1.618-3.047a4.08 4.08 0 0 1 .524-1.8l-.825.07a12.188 12.188 0 0 0 8.81 4.515l.59.033-.06-.59v-.02c-.05-.43-.06-.63-.06-.87a3.617 3.617 0 0 1 6.27-2.45l.2.21.28-.06c1.01-.22 1.94-.59 2.73-1.09l-.75-.56c-.1.36-.04.89.12 1.36.23.68.58 1.13 1.17.85l-.21-.45-.42-.27c-.52.8-1.17 1.48-1.92 2L22 11l.016.28c.013.2.014.35 0 .52v.04zm.998.038c.018-.22.017-.417 0-.66l-.498.034.284.41a8.183 8.183 0 0 0 2.2-2.267l.97-1.48-1.6.755c.17-.08.3-.02.34.03a.914.914 0 0 1-.13-.292c-.1-.297-.13-.64-.1-.766l.36-1.254-1.1.695c-.69.438-1.51.764-2.41.963l.48.15a4.574 4.574 0 0 0-3.38-1.484 4.616 4.616 0 0 0-4.61 4.613c0 .29.02.51.08.984l.01.02.5-.06.03-.5c-3.17-.18-6.1-1.7-8.08-4.15l-.48-.56-.36.64c-.39.69-.62 1.48-.65 2.28.04 1.61.81 3.04 2.06 3.88l.3-.92c-.55-.02-1.11-.17-1.6-.45l-.59-.34-.14.67c-.02.08-.02.16 0 .24-.01 2.12 1.55 4.01 3.69 4.46l.1-.49-.1-.49c-.33.07-.67.12-1.03.14-.18-.02-.43-.05-.64-.07l-.76-.09.23.73c.57 1.84 2.29 3.14 4.28 3.21l-.28-.89a8.252 8.252 0 0 1-4.85 1.66c-.12-.01-.26-.02-.56-.05l-.17-.01-.18-.01L2.53 21l1.694 1.07a12.233 12.233 0 0 0 6.58 1.917c7.156 0 12.2-5.73 12.18-12.18l-.002.04z"></path></svg>
      </span>
    </a>

    &nbsp;&nbsp;&nbsp;
    <!-- Facebook -->
    <a href="http://www.facebook.com/sharer.php?u=https://thereviewindex.com/blog/2019/11/12/04-01-keras/" target="_blank">
      <span class="social-icon">
        <svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M16.39 23.61v-5.808h1.846a.55.55 0 0 0 .546-.48l.36-2.797a.551.551 0 0 0-.547-.62H16.39V12.67c0-.67.12-.813.828-.813h1.474a.55.55 0 0 0 .55-.55V8.803a.55.55 0 0 0-.477-.545c-.436-.06-1.36-.116-2.22-.116-2.5 0-4.13 1.62-4.13 4.248v1.513H10.56a.551.551 0 0 0-.55.55v2.797c0 .304.248.55.55.55h1.855v5.76c-4.172-.96-7.215-4.7-7.215-9.1 0-5.17 4.17-9.36 9.31-9.36 5.14 0 9.31 4.19 9.31 9.36 0 4.48-3.155 8.27-7.43 9.15M14.51 4C8.76 4 4.1 8.684 4.1 14.46c0 5.162 3.75 9.523 8.778 10.32a.55.55 0 0 0 .637-.543v-6.985a.551.551 0 0 0-.55-.55H11.11v-1.697h1.855a.55.55 0 0 0 .55-.55v-2.063c0-2.02 1.136-3.148 3.03-3.148.567 0 1.156.027 1.597.06v1.453h-.924c-1.363 0-1.93.675-1.93 1.912v1.78c0 .3.247.55.55.55h2.132l-.218 1.69H15.84c-.305 0-.55.24-.55.55v7.02c0 .33.293.59.623.54 5.135-.7 9.007-5.11 9.007-10.36C24.92 8.68 20.26 4 14.51 4"></path></svg>
      </span> 
    </a>
  </div>

  <!-- Facebook Comments HTML -->
  <div class="m-t-6e">
    <div class="fb-comments" data-href="http://localhost:4000/2019/11/12/04-01-keras/" data-width="800" data-numposts="5"></div>
  </div>

</article>


  
  	  </main>
  		
  		  <!-- Pagination links -->
        
  
  	  </div>
  	    
  	    <!-- Footer -->
        <div class="m-t-6e">
          <footer><span>&#169;2017 - TheReviewIndex</span></footer>

        </div>
  
  	    <!-- Script -->
        <script src="/js/main.js"></script>	

  
    </div>
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-118401942-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-118401942-1');
</script>
  </body>
</html>
