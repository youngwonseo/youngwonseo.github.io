<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    
      딥러닝의 역전파 &middot; Youngwon Seo
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png">
</head>

  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-118401942-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-118401942-1');
</script>

  <body>
    <nav class="nav">
      <div class="nav-container">
        <a href="/">
          <h2 class="nav-title">Youngwon Seo</h2>
        </a>
        <ul>
          <li><a href="/about">About</a></li>
          <li><a href="/">Posts</a></li>
          <li><a href="/study"/>Study</a></li>
          <li><a href="/ml"/>Machine Learning</a></li>
          <li><a href="/gcp"/>GCP</a></li>
          <!-- <li><a href="/spring"/>Spring</a></li>
          <li><a href="/deeplearning"/>Deeplearning</a></li> -->
        </ul>
    </div>
  </nav>

    <main>
      <div class="post">
  <div class="post-info">
    <span>Written by</span>
    
        Youngwon Seo
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2019-08-01 00:00:00 +0900">August 01, 2019</time>
    
  </div>

  <h1 class="post-title">딥러닝의 역전파</h1>
  <div class="post-line"></div>

  <p>여기서는 역전파의 기본원리를 알아보겠습니다. 이를 위해 계산 그래프(computational graph)를 이용합니다. 계산 그래프는 계산과정을 그래프(node와 edge로 구성)구조로 나타내는 것을 의미합니다. 일반적인 수식으로 이해하는 것보다 좀더 직관적이고 쉽게 이해할 수 있는 장점이 있습니다.</p>

<p>또한 신경망과 비용함수, 경사하강법등의 기본지식을 알고 있다고 가정하고 설명을 진행합니다.</p>

<h1 id="계산-그래프">계산 그래프</h1>
<p>먼저 계산그래프의 예를 살펴보겠습니다. 다음과 같은 문장을 계산그래프로 나타낸다고 생각해 봅시다.</p>

<blockquote>
  <p>문제1 : 현빈 군은 슈퍼에서 1개에 100원인 사과를 2개샀습니다. 여기서는 소비세가 10%부과 됩니다.</p>
</blockquote>

<p>계산그래프로는 다음과 같이 표현됩니다.</p>

<p><img src="/public/deep_learning_images/fig 5-1.png" alt="" /></p>

<p>어떤가요 ? 먼저 사과한개인 100이 입력되면 각 노드(node)에서 계산에 필요한 연산(operation)이 실행됩니다. 마지막에는 결국 각 연산을 수행한 결과가 출력됩니다. 여기서 노드에 입력되어 있는 상수(피연산자)를 입력으로 처리하면 다음과 같이 표현할 수 있습니다.</p>

<p><img src="/public/deep_learning_images/fig 5-2.png" alt="" /></p>

<p>사과의 개수에 해당하는 2와 소비세 계산을 위한 1.1을 입력으로 처리하고 각 노드는 완전히 연산자(operator)만 포함하고 있습니다.</p>

<p>여기서 한 가지 포인트는 계산그래프의 계산이 왼쪽에서 오른쪽으로 진행된다는 점입니다. 이것은 신경망에서 입풋에서 아웃풋으로 계산이 진행되면서 cost 를 출력하는 순전파(forward propagation)와 동일한 형태입니다. 즉 신경망에서 수행되는 연산을 계산그래프로 표현이 가능하다는 것이죠. 또한 <strong>역전파(back propagation)라는 것은 결국 계산그래프가 오른쪽에서 왼쪽으로 진행되며 연산(미분)을 하는것을 의미</strong>합니다. 이것이 학습에 대한 기본원리입니다. 연산을 거꾸로 진행하는것인데 아직까지는 이해가 안갈 수 있습니다. 이를 이해하기위해 먼저 연쇄법칙을 알아보겠습니다,</p>

<h1 id="연쇄-법칙">연쇄 법칙</h1>
<p>연쇄 법칙(chanin rule)이란 합성함수에서의 미분표현을 위해 사용되는 원칙입니다. z = (x + y)^2 와 같은 수식은 다음과 같이 분리해서 표현가능합니다.
<img src="/public/deep_learning_images/e 5.1.png" alt="" /></p>

<p>측 하나의 함수가 2개의 함수로 분리를 했는데 이러한 함수(z = (x + y)^2)를 합성함수라고 표현할 수 있으며 합성함수에 대한 미분을 계산하기 위해서는 다음과 같은 규칙이 있습니다.</p>

<blockquote>
  <p>합성 함수의 미분은 합성함수를 구성하는 각 함수의 비분의 곱으로 나타낼 수 있다.</p>
</blockquote>

<p>즉 z = (x + y)^2 함수는 위 수식의 z와 t로 표현가능한 합성함수인데 이의 미분은 z의 미분과 t의 미분의 곱으로 표현가능합니다.</p>

<p><img src="/public/deep_learning_images/e 5.2.png" alt="" /></p>

<p>여기서 우편의 기호는 각각 t에 대한 z의 미분, x에 대한 t의 미분(편미분)입니다. 그리고 각각의 미분을 값으로 표현하면 다음과 같습니다.</p>

<p><img src="/public/deep_learning_images/e 5.4.png" alt="" /></p>

<p>t^2을 t에 대해 미분하면 2t, x+y를 x에 대해 미분하면 1이기 때문에 이들의 곱, 2t x 1이어서 2t가 결과적으로 구해집니다.</p>

<p>이를 계산그래프로 표현하면 다음과 같습니다(위는 미분기호, 아래는 실제 값).</p>

<p><img src="/public/deep_learning_images/fig 5-7.png" width="400" /></p>

<p><img src="/public/deep_learning_images/fig 5-8.png" width="400" /></p>

<p>제곱과 더하기로 이루어진 합성함수를 계산그래프로 나타내고 이것을 미분하는것을 보였습니다. 계산 그래프는 이처럼 여러개의 함수들이 합성되어 있을때 미분을 쉽게 계산하도록 표현할 수 있습니다. 위 계산그래프는 z = (x + y)^2를 나타내고 이것의 미분이 2(x+y) x 1 이라는것을 보입니다.</p>

<h1 id="신경망의-역전파">신경망의 역전파</h1>
<p>신경망의 순전파는 곱셈과 더하기가 먼저 수행되며 다음으로 활성화 함수를 통과하며 수행됩니다. 그럼 역전파는 결국 이러한 연산을 거꾸로 타고 올라오며 미분을 적용하는것인데 이것을 살펴보겠습니다.</p>

<h2 id="덥셈의-역전파">덥셈의 역전파</h2>
<p>덧셈 z = x + y을 x과 y에 대한 z의 미분(편미분)을 구하면 각각 1이 됩니다.
<img src="/public/deep_learning_images/e 5.5.png" alt="" /></p>

<p>이를 계산 그래프로 표현하면 다음과 같습니다.</p>

<p><img src="/public/deep_learning_images/fig 5-9.png" width="500" />
입력 x와 y가 있고 노드에서 더하기 연산의 결과로z를 출력합니다. 역전파로 표현하면 이의 출력에 대한 Loss를 실제 출력 z에 대해 미분하고 각각의 입력(x,y)으로 역전파하면 결국 똑같은값(x1)이 역전파로 흘러가는것과 같습니다. 구체적인 값으로 표현하면 다음과 같습니다.</p>

<p><img src="/public/deep_learning_images/fig 5-11.png" width="500" />
10과 5가 입력되어 15가 출력되는 계산그래프에서 loss의 미분이 1.3일때(이것은 임의의값) 그냥 그대로 1.3으로 흘려보낸다는 것이죠. 1.3이라는 숫자는 신경쓸 필요가 없습니다. 일단 그냥 그대로 흘려보낸다는것에 집중하기를 바랍니다.</p>

<h2 id="곱셉의-역전파">곱셉의 역전파</h2>
<p>곱셈은 z = xy가 존재할 때 각각의 미분이 다음과 같습니다. 상수가 남아 각각 반대로 흘러가는것이죠.</p>

<p><img src="/public/deep_learning_images/e 5.6.png" alt="" /></p>

<p><img src="/public/deep_learning_images/fig 5-12.png" width="500" /></p>

<p>구체적인 숫자로 표현하면 다음과 같습니다.
<img src="/public/deep_learning_images/fig 5-13.png" width="500" /></p>

<p>이전 사과구매(한개에 100, 2개구매, 1.1의 소비세)의 역전파를 나타내면 다음과 같습니다.
<img src="/public/deep_learning_images/fig 5-14.png" width="500" /></p>

<p>사과가격의 미분은 2.2, 사과 개수의 미분은 110, 소비세의 미분은 200입니다. 사과가격이 오르면 최종금액에 2.2의 크기로, 개수가오르면 110의 크기로, 소비세가 오르면 200의 크기로 결과에 영향을 준다는것으로 해석할 수 있습니다(개수와 소비세는 1당 100%, 가격은 1원이라는 단위는 다릅니다).</p>

<h2 id="relu-역전파">Relu 역전파</h2>
<p>Relu는 입력이 0보다 크면 그냥, 0보다 작으면 0을 출력하는 활성화 함수입니다. 이에 대한 미분결과는 x가 0보다 크면 1, 0보다 작으면 0을 보냅니다. 즉 그냥 역전파 또는 0을 역전파 둘중에 하나입니다.</p>

<p><img src="/public/deep_learning_images/fig 5-18.png" width="500" /></p>

<h2 id="sigmoid-역전파">Sigmoid 역전파</h2>
<p>sigmoid는 다음과 같은 식입니다.</p>

<p><img src="/public/deep_learning_images/e 5.9.png" alt="" /></p>

<p>갑자기 뭔가 복잡해 보이지만 결국 합성함수로써 다음과 같이 계산그래프로 표현(어떠한 함수든 계산그래프로 표현하고 이를 거꾸로 미분하면 역전파가 되는것이 계산그래프의 장점)됩니다.</p>

<p><img src="/public/deep_learning_images/fig 5-19.png" width="500" /></p>

<p>여기에는 exp와 /도 보이는데 이것도 일반적인 미분을 하면되죠(이러한 미분에 대한 상세사항(고등학교 수학)은 검색을 통해 알수있습니다).</p>

<p>즉 최종적으로는 다음과 같은 미분결과를 얻을 수 있습니다.</p>

<p><img src="/public/deep_learning_images/fig 5-20.png" width="500" /></p>

<h1 id="references">References</h1>
<ul>
  <li><a href="http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&amp;mallGb=KOR&amp;barcode=9788968484636&amp;orderClick=LAG&amp;Kc=">밑바닥부터 시작하는 딥러닝</a></li>
</ul>


  
  <div class="post-disqus">
      <section id="disqus_thread"></section>
      <div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://youngwonseo.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
                            
  </div>
  
</div>

<div class="pagination">
  
    <a href="/2019/08/08/data-tensor/" class="left arrow">&#8592;</a>
  
  
    <a href="/2019/07/31/ml-references/" class="right arrow">&#8594;</a>
  

  <a href="#" class="top">Top</a>
</div>

    </main>

    <footer>
      <span>
        &copy; <time datetime="2019-08-20 15:58:37 +0900">2019</time> Youngwon Seo. Made with Jekyll using the <a href="https://github.com/chesterhow/tale/">Tale</a> theme.
      </span>
    </footer>
  </body>
</html>
