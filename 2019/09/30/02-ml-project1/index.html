<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta https-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width initial-scale=1">

  <title>머신러닝 프로젝트 처음부터 끝까지#1</title>
  <meta name="description" content="이번 장에서는 머신러닝의 프로세스를 처음부터 끝까지 경험해보며 각 과정에서 나타나는 이슈나 고려할 점등을 경험하는 장입니다. 개인적으로 이러한 전체 플로우를 미리보고 각 과정의 디테일한 요소를 공부하는 방식이 머신러닝을 공부하기 가장 좋은 방법이라고 생각합니다.">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://youngwonseo.github.io/2019/09/30/02-ml-project1/">
  <link rel="alternate" type="application/atom+xml" title="YoungWon" href="https://youngwonseo.github.io/feed.xml" />
</head>

  <body>
    

<div class="header-container" id="header-container">

<!-- Site navigation -->
  <nav class="site-nav">
    <div class="trigger">
      
        
        <a class="page-link" href="/about/">About</a>
        
      
        
        <a class="page-link" href="/archive/">Archive</a>
        
      
        
      
        
      
        
        <a class="page-link" href="/projects/">Projects</a>
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
      <a class="page-link" href="/feed.xml">RSS</a>
      <!-- <a class="twitter page-link" href="httpss://twitter.com/fffabs"><span class="icon-twitter"></span></a>
      <a class="facebook page-link" href="httpss://www.facebook.com/fffabs"><span class="icon-facebook"></span></a> -->
    </div>
  </nav>

  <!-- The title of the site -->
  <header class="site-header">
    <!-- <a href="/">
      <div class="trigger">
        <img src="/assets/images/avatar.png" />
      </div>
    </a> -->
    <a class="site-title" href="/">YoungWon</a> -->
  </header>

</div>

      <div class="wrapper">
        <div class="page-content">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">머신러닝 프로젝트 처음부터 끝까지#1</h1>
    <p class="post-meta">September 30, 2019 • Youngwon Seo</p>
  </header>

  <!-- Beginning Twitter sharing Large button -->
  <!-- <a class="twitter-share-button" href="httpss://twitter.com/share"
  data-related="twitterdev"
  data-size="large"
  data-count="horizontal">
  Tweet
  </a> -->
  <!-- End of Twitter sharing button -->

  <!-- Facebook -->
  

  <article class="post-content">
    <p>이번 장에서는 머신러닝의 프로세스를 처음부터 끝까지 경험해보며 각 과정에서 나타나는 이슈나 고려할 점등을 경험하는 장입니다. 개인적으로 이러한 전체 플로우를 미리보고 각 과정의 디테일한 요소를 공부하는 방식이 머신러닝을 공부하기 가장 좋은 방법이라고 생각합니다.</p>

<p>다음은 이번장에서 경험할, 그리고 머신러닝 프로젝트에서 진행되는 주요 과정들입니다.</p>
<ol>
  <li>큰 그림을 봅니다.</li>
  <li>데이터를 구합니다.</li>
  <li>데이터로 부터 통찰을 얻기 위해 데이터를 준비합니다.</li>
  <li>머신러닝 알고리즘을 위해 데이터를 준비합니다.</li>
  <li>모델을 생성하고 훈련시킵니다.</li>
  <li>모델을 상세하게 조정합니다.</li>
  <li>솔루션을 제시합니다.</li>
  <li>시스템을 런칭하고 모니터링하고 유지보수합니다.</li>
</ol>

<p>그럼 이제 각 과정을 살펴봅시다. 내용이 다소 길어 두개의 포스트에 나눠서 작성하였습니다.
모든 실습은 Google의 Colabaratory에서 실행하였습니다.</p>

<h2 id="1-큰-그림-보기">1. 큰 그림 보기</h2>
<p>머신러닝 프로젝트의 전체 과정을 경험하기 위해 여기서는</p>
<ul>
  <li>사용데이터 : 캘리포니아 인구조사 데이터()</li>
</ul>

<h3 id="목적">목적</h3>

<h2 id="2-데이터-가져오기">2. 데이터 가져오기</h2>
<p>데이터를 가져오기 위해 웹브라우저를 통해 다운받고 압출을 풀어 사용할 수도 있지만 여기서는 파이썬 스크립트를 통해 다운을받고 처리하는 형태로 진행합니다. 이렇게 스크립트를 사용하여 자동화하면 다른 데이터셋을 다운받을때에서 편리하게 사용할 수 있습니다.</p>

<pre><code class="language-python">import os
import tarfile
from six.moves import urllib

DOWNLOAD_ROOT = "httpss://raw.githubusercontent.com/ageron/handson-ml/master/"
HOUSING_PATH = os.path.join("datasets", "housing")
HOUSING_URL = DOWNLOAD_ROOT + "datasets/housing/housing.tgz"

def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):
  if not os.path.isdir(housing_path):
    os.makedirs(housing_path)
  tgz_path = os.path.join(housing_path, "housing.tgz")
  urllib.request.urlretrieve(housing_url, tgz_path)
  housing_tgz = tarfile.open(tgz_path)
  housing_tgz.extractall(path=housing_path)
  housing_tgz.close()

fetch_housing_data()
</code></pre>
<p>코드를 설명하명 다음과 같습니다.</p>
<ul>
  <li>fetch_housing_data함수는 파라미터로 입력되는 URL에 대한 데이터에 접근하여 PATH 디렉토리에 다운을 받습니다.</li>
  <li>PATH로 입력된 디렉토리가 존재하지 않으면 생성합니다.</li>
  <li>urllib.request.urlretrieve을 통해 URL에 접근합니다.</li>
</ul>

<p>다음은 csv형태로 존재하는 데이터를 Pandas의 DataFrame으로 변형합니다.</p>

<pre><code class="language-python">import pandas as pd

def load_housing_data(housing_path=HOUSING_PATH):
  csv_path = os.path.join(housing_path, "housing.csv")
  return pd.read_csv(csv_path)

housing = load_housing_data()
</code></pre>
<p>DataFrame은 파이썬에서 기본적으로 제공하는 배열이나 리스트같은 자료구조 보다 데이터 분석에 있어서 더 강력한 기능들을 제공합니다.</p>

<p>이후 위에서 DataFrame에서 제공하는 info함수를 통해 데이터의 특성(columns, feature라고도하고도 함)들을 살펴봅시다.</p>
<pre><code class="language-python">housing.info()
</code></pre>
<pre>
&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 20640 entries, 0 to 20639
Data columns (total 10 columns):
longitude             20640 non-null float64
latitude              20640 non-null float64
housing_median_age    20640 non-null float64
total_rooms           20640 non-null float64
total_bedrooms        20433 non-null float64
population            20640 non-null float64
households            20640 non-null float64
median_income         20640 non-null float64
median_house_value    20640 non-null float64
ocean_proximity       20640 non-null object
dtypes: float64(9), object(1)
memory usage: 1.6+ MB
</pre>

<p>전체 데이터는 20640개 이고 각 데이터는 10개의 column을 가지는 군요!</p>

<p>그럼 이제 머신러닝 모델학습과 평가를 위해 데이터를 학습데이터와 테스트데이터로 나누겠습니다. 이렇게 데이터를 나누는 이유는 모델의 학습하고 평가할때 같은 데이터를 사용하면 당연히 좋은 결과가 나올수 밖에 없기 때문입니다. 시험이 기출문제에서 나오면 공부하고 시험치기 쉬운 거랑 같은 원리죠, 이 부분은 모델 선택과 훈련부분에서 자세히 살펴보겠습니다.</p>

<p>여기서는 sckitlearn에서 제공하는 data split함수를 사용하겠습니다.</p>
<pre><code class="language-python">from sklearn.model_selection import train_test_split
train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)
</code></pre>
<p>파라미터는 기존데이터셋, 전체 데이터에서 테스트 데이터의 비율, 랜덤 시드(이 값이 같으면 매번 똑같은 데이터로 split을 합니다)값입니다. train_test_split은 이러한 매개변수를 받고 전체 데이터셋에서 <strong>무작위</strong>로 학습데이터셋과 테스트데이터셋을 만들어 반환합니다.</p>

<p>데이터가 충분히 크면 무작위로 데이터를 선핵하면 되지만 그렇지 못할때, 예로 들면 전체 인구중 1000명에게 설문조사를 할때, 연령별, 성별, 거주지별 등 조사 목적에 적합하게 전체 인구를 대표할 수 있는 1000명을 선택하는 것이 중요합니다. 그리고 이것을 계층적 샘플링(stratified sampling)이라고 합니다.</p>

<pre><code class="language-python">import numpy as np
from sklearn.model_selection import StratifiedShuffleSplit

split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for train_index, test_index in split.split(housing, housing["income_cat"]):
  strat_train_set = housing.loc[train_index]
  strat_test_set = housing.loc[test_index]
</code></pre>

<pre><code class="language-python">housing["income_cat"].value_counts() / len(housing)
</code></pre>
<p>3.0    0.350581
2.0    0.318847
4.0    0.176308
5.0    0.114438
1.0    0.039826
Name: income_cat, dtype: float64</p>

<p>데이터 샘플링을 마치면 샘플링을 위해 만들었던 imcome_cat을 삭제합니다.</p>
<pre><code class="language-python">for set_ in (strat_train_set, strat_test_set):
  set_.drop("income_cat", axis=1, inplace=True)
</code></pre>

<h2 id="3-데이터-탐색시각화">3. 데이터 탐색&amp;시각화</h2>
<p><strong>데이터 분석에 앞서 데이터의 특징들을 살펴보는것은 매우 중요한 작업니다</strong>. 즉 데이터가 주어지고 목적이 주어졌을때 어떤 모델을 사용하고 어떤 하이퍼파라미터를 사용하는가는 데이터의 특성(데이터의 형태나 모양)에 따라 결정됩니다(목적에 따라 모델이 결정될 수도 있습니다). 이러한 작업을 데이터 탐색이라하고 보통은 통계의 기본적인 도구들을 활용해 살펴보거나 또는 데이터를 시각화해서 눈으로 살펴봅니다.</p>

<p>여기서는 앞단계에서 분리했던 학습데이터셋을 가지고 데이터탐색 및 시각화 작업을 진행하겠습니다. 먼저 원본데이터가 손상되지 않도록 복사본을 준비합니다.</p>

<pre><code class="language-python">housing = strat_train_set.copy()
</code></pre>

<h3 id="지리적">지리적</h3>
<p>첫 번째로 할 작업은 데이터의 시각화입니다. 여기서 사용되는 인구조사데이터는 위도와 경도를 포함하고 있습니다. 
먼저 위경도를 기반으로 산점도를 만들어 봅시다.</p>
<pre><code>housing.plot(kind="scatter", x="longitude",y="latitude")
</code></pre>
<p><img src="/public/hands-on-ml/02-03.png" alt="" /></p>

<p>이 지역은 캘리포니아를 나타냅니다. 겹쳐진 지역은 정확하게 산점도를 확인할 수 없는데 alpha 옵션에 0.1을 주고실행해 봅니다.</p>
<pre><code>housing.plot(kind="scatter", x="longitude",y="latitude", alpha=0.1)
</code></pre>
<p><img src="/public/hands-on-ml/02-04.png" alt="" />
확실히 나아졌습니다. 베이 에어리어, 로스앤젤레스 등의 <strong>큰도시가 존재하는 위치에 진하게 표현</strong>된것을 확인할 수 있습니다.</p>

<p>이번에는 주택가격에 대한 산점도를 나타냅니다. 다음과 같은 특성으로 시각화합니다.</p>
<ul>
  <li>원의 반지름 : 구역의 인구</li>
  <li>색깔 : 가격(빨간색 - 높음, 파란색 - 낮음)</li>
</ul>

<pre><code class="language-python">housing.plot(kind="scatter", x="longitude", y="latitude", alpha=0.4, s=housing["population"]/100, label="population", figsize=(10,7),c="median_house_value", cmap=plt.get_cmap("jet"), colorbar=True, sharex=False)
plt.legend()
</code></pre>
<p><img src="/public/hands-on-ml/02-05.png" alt="" />
위 그림을 보면 <strong>해안가와 인접한 위치의 주택들의 가격이 높다</strong>는 것을 확인할 수 있습니다.</p>

<p>이때까지의 탐색으로 큰도시 그리고 해안가일 수록 주택이 많고 가격이 높다는 것을 확인하였습니다. 이처럼 머신러닝 모델을 학습하기전 데이터의 특성을 알아가는것, 즉 도메인 레벨에서 데이터의 특성을 분석하는것은 데이터 과학에서 매우 중요한 과정이고 필수적인 과정입니다.</p>

<p>이번에는 상관관계를 살펴보겠습니다.
상관관계는 데이터의 특징(feature)간의 연관관계를 나타냅니다. 이를 위해 표준 상관계수(standard correlation coefficient, 피어슨의 r)을 계산합니다. 여기서는 <strong>중간주택가격과 다른 특징간의 상관계수</strong>를 계산합니다.</p>

<pre><code class="language-python">corr_matrix = housing.corr()
corr_matrix["median_house_value"].sort_values(ascending=False)
</code></pre>
<pre>
median_house_value          1.000000
median_income               0.687160
rooms_per_household         0.146285
total_rooms                 0.135097
housing_median_age          0.114110
households                  0.064506
total_bedrooms              0.047689
population_per_household   -0.021985
population                 -0.026920
longitude                  -0.047432
latitude                   -0.142724
bedrooms_per_room          -0.259984
Name: median_house_value, dtype: float64
</pre>

<p>상관관계는 -1부터 1까지로 표현됩니다. 각 특성은 다음과 같습니다.</p>
<ul>
  <li>1에 가까우면 : 양의 상관관계, A가 오르면 B도 오름</li>
  <li>-1에 가까우면 : 음의 상관관계, A가 오르면 B는 내림</li>
  <li>0에 가까우면 : 상관관계가 없음</li>
</ul>

<p>다음글</p>

<h2 id="references">References</h2>
<ul>
  <li><a href="https://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&amp;mallGb=KOR&amp;barcode=9791162240731&amp;orderClick=LEa&amp;Kc=">핸즈온 머신러닝(오렐리앙 제롱 지음, 박해선 옮김) - 한빛미디어</a></li>
</ul>

  </article>

  <hr>

  
  <!-- <div class="question">
    <h2>Questions?</h2>
    <p>Have a question regarding the post above? <br />Or any of my designs?</p>
    <a class="twitter-follow-button"
    href="httpss://twitter.com/fffabs"
    data-show-count="true"
    data-size="large">
    Follow @fffabs
    </a>
    <script type="text/javascript">
    window.twttr = (function (d, s, id) {
      var t, js, fjs = d.getElementsByTagName(s)[0];
      if (d.getElementById(id)) return;
      js = d.createElement(s); js.id = id;
      js.src= "httpss://platform.twitter.com/widgets.js";
      fjs.parentNode.insertBefore(js, fjs);
      return window.twttr || (t = { _e: [], ready: function (f) { t._e.push(f) } });
    }(document, "script", "twitter-wjs"));
    </script>
  </div> -->

  <div class="related">
    <h2>Related</h2>
    
      <li><a href="/2020/11/11/detecting-aortic-stenosis-using-electrocardiography/" title="Detecting Aortic Stenosis Using Electrocardiography">Detecting Aortic Stenosis Using Electrocardiography
       &nbsp; <span class="post-meta">November 11, 2020</span></a>
    
      <li><a href="/2020/10/09/image-resize/" title="파이썬 이미지 리사이즈">파이썬 이미지 리사이즈
       &nbsp; <span class="post-meta">October 09, 2020</span></a>
    
      <li><a href="/2020/09/22/class-activation-map/" title="Learning Deep Features for Discriminative Localization">Learning Deep Features for Discriminative Localization
       &nbsp; <span class="post-meta">September 22, 2020</span></a>
    
  </div>

</div>

        </div>
        <footer class="site-footer">
<p class="small">YoungwonSeo &copy 2020
</p>
</footer>

    </div>

    <script src="//cdn.jsdelivr.net/headroomjs/0.5.0/headroom.min.js"></script>
    <script type="text/javascript">
      var el = document.querySelector(".header-container");
      var headroom  = new Headroom(el, {
        "offset": 205,
        "tolerance": 5
      });
      headroom.init();
    </script>


    <!-- Twitter Shizzle -->
    <!-- <script type="text/javascript">
    window.twttr = (function (d, s, id) {
      var t, js, fjs = d.getElementsByTagName(s)[0];
      if (d.getElementById(id)) return;
      js = d.createElement(s); js.id = id;
      js.src= "httpss://platform.twitter.com/widgets.js";
      fjs.parentNode.insertBefore(js, fjs);
      return window.twttr || (t = { _e: [], ready: function (f) { t._e.push(f) } });
    }(document, "script", "twitter-wjs"));
    </script> -->
    	<!-- Google Analytics -->
  <script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','httpss://www.google-analytics.com/analytics.js','ga');
		
		ga('create', 'UA-78263144-1', 'auto');
		ga('send', 'pageview');
		</script>
		<!-- End Google Analytics -->
</header>


  </body>
</html>
