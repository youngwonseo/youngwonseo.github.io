<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="http://youngwonseo.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="http://youngwonseo.github.io/" rel="alternate" type="text/html" /><updated>2020-08-20T14:06:32+09:00</updated><id>http://youngwonseo.github.io/feed.xml</id><title type="html">Youngwon Seo</title><author><name>Youngwon Seo</name><email>jazz9008@gmail.com</email></author><entry><title type="html">Evaluation of Combined Artificial Intelligence and Radiologist Assessment to Interpret Screening Mammograms</title><link href="http://youngwonseo.github.io/2020/08/16/mammograms/" rel="alternate" type="text/html" title="Evaluation of Combined Artificial Intelligence and Radiologist Assessment to Interpret Screening Mammograms" /><published>2020-08-16T00:00:00+09:00</published><updated>2020-08-16T00:00:00+09:00</updated><id>http://youngwonseo.github.io/2020/08/16/mammograms</id><content type="html" xml:base="http://youngwonseo.github.io/2020/08/16/mammograms/">&lt;h2 id=&quot;논문링크&quot;&gt;논문링크&lt;/h2&gt;
&lt;p&gt;https://jamanetwork.com/journals/jamanetworkopen/articlepdf/2761795/schaffter_2020_oi_200024.pdf&lt;/p&gt;

&lt;h2 id=&quot;abstrct&quot;&gt;Abstrct&lt;/h2&gt;
&lt;h3 id=&quot;importance&quot;&gt;Importance&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;현재 유방 조영술 검사는 사람의 주관적인 해석에 의존&lt;/li&gt;
  &lt;li&gt;AI는 유방 조영술 검사 중 암 발견을 놓치거나, 검사에 대한 false positive를 줄여 유방 조영술 검사에 대한 정확도를 높힐 수 있음&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;objective&quot;&gt;Objective&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;AI가 유방 조영술 검사에 대해 사람의 검사 능력을 능가하는지 평가&lt;/li&gt;
  &lt;li&gt;또한 여러 무작위 임상시험에서 사망률을 가장 낮추는 방법&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;design-setting-and-paricipants&quot;&gt;Design, Setting, and Paricipants&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;2016.09 ~ 2017.11 유방 조영술 검사를 설명하기 위한 대회(클라우드소싱기반)에서 수행&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;main-outcomes-and-measurements&quot;&gt;Main Outcomes and Measurements&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;다음을 인풋으로 12개월 안에 암전이에 대한 모델
    &lt;ul&gt;
      &lt;li&gt;images(challenge1)&lt;/li&gt;
      &lt;li&gt;combined images&lt;/li&gt;
      &lt;li&gt;previous examinations&lt;/li&gt;
      &lt;li&gt;clinical and demograpic risk factor data(challenge2)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;results&quot;&gt;Results&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;144,231 검사결과(85,580의 미국여성)가 사용됨&lt;/li&gt;
  &lt;li&gt;second independent validation cohort, 166,578 examinations(68,008 스웨덴여성)&lt;/li&gt;
  &lt;li&gt;top-performing AUC - 0.858(US), 0.903(Sweden)&lt;/li&gt;
  &lt;li&gt;66.2%(US), 81.2(Sweden) specificity&lt;/li&gt;
  &lt;li&gt;radiologists’ specificity, sensitivity 85.9%(US), 83.9%(Sweden)&lt;/li&gt;
  &lt;li&gt;앙상블기반의 aggregating의 성능과 radiologists의 recall를 평가&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;conclusions-and-relevance&quot;&gt;Conclusions and Relevance&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;하나의 AI알고리즘은 radiologist를 능가하지 못했지만 앙상블 모델과 radiologist의 평가는 정확도가 개선됨, single-reader screening environment에서&lt;/li&gt;
  &lt;li&gt;유방망 조영술 설명에 대한 머신러닝 알고리즘의 가능성을 보여줌&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;유방조영술검사(Mammography screening)은 조기 유방암 발견을 위해 가장 넓게 배포되어있고 사용되는 도구&lt;/li&gt;
  &lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Youngwon Seo</name></author><summary type="html">논문링크 https://jamanetwork.com/journals/jamanetworkopen/articlepdf/2761795/schaffter_2020_oi_200024.pdf</summary></entry><entry><title type="html">[길벗] 신경망 교과서 리뷰</title><link href="http://youngwonseo.github.io/2020/07/07/nerual-network-projects/" rel="alternate" type="text/html" title="[길벗] 신경망 교과서 리뷰" /><published>2020-07-07T00:00:00+09:00</published><updated>2020-07-07T00:00:00+09:00</updated><id>http://youngwonseo.github.io/2020/07/07/nerual-network-projects</id><content type="html" xml:base="http://youngwonseo.github.io/2020/07/07/nerual-network-projects/">&lt;p&gt;본 글은 이번에 길벗에서 출간(번역)한 &lt;a href=&quot;http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&amp;amp;mallGb=KOR&amp;amp;barcode=9791165211639&amp;amp;orderClick=LAG&amp;amp;Kc=&quot;&gt;신경망 교과서&lt;/a&gt;에 대한 리뷰글입니다.&lt;/p&gt;

&lt;h2 id=&quot;머신러닝과-신경망&quot;&gt;머신러닝과 신경망&lt;/h2&gt;
&lt;p&gt;본 도서는 제목에 걸맞게 신경망을 중점적으로 다루고 있습니다. 1장에는 아주 기본적인 머신러닝 이론들을 살짝 맛보지만 2장이후 데이터 전처리, 학습/검증/테스트 데이터 나누기, 기본적인 신경망 아키텍처 구성, Confusion matrix, ROC Curve등 개념을 익혀 추후 실전 프로젝트에서 사용가능한 머신러닝의 기본적인 배경지식을 익힐 수 있습니다. 기존에 이론적 서적들이 읽기 힘겨웠던 분들은 본 책을 통해 예제기반으로 이해하시면 좋을 것 같습니다. 하지만 조금은 깊게 공부하시고 싶으신분들은 이책과 함께 추가적으로 머신러닝책을 참조하시면 정말 좋을것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;케라스&quot;&gt;케라스&lt;/h2&gt;
&lt;p&gt;본 도서의 예제는 케라스로 구성되어 있습니다. 케라스는 오픈되어있는 딥러닝 프레임워크중 가장 직관적이라고 할 수 있으며 딥러닝 입문자들에게도 매우 적합한 도구입니다. 여기서 직관적이다라는 말은 딥러닝을 코드로 표현하는데 있어서 입니다. 이것이 무조건 장점으로 작용하는건 아니지만 입문자들에게는 최고의 환경입니다! 본 도서로 케라스를 익히면 온라인상에 공유된 케라스 코드를 공유하는데 문제가 없습니다. 다만 최근 텐서플로우2와 케라스가 통합이되면서 같이 사용되는경우가 존재하지만 배우는데 있어서는 문제가 없습니다. 케라스와 함께 데이터전처리나 시각화를 위해 판다스, 사이킷런등의 라이브러리 또한 익힐수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;mlp-convolutional-neural-network-recurrent-nerual-network&quot;&gt;MLP, Convolutional Neural Network, Recurrent Nerual Network&lt;/h2&gt;
&lt;p&gt;신경망의 핵심이라고 할 수 있는 여러가지 딥러닝 아키텍처를 기반으로한 예제들을 살펴볼 수 있습니다. 신경망의 가장 기본적 아키텍처라 할수 있는 MLP(다중 레이어 퍼셉트론)부터 합성곱 신경망, 순환신경망(책에서는 LSTM)을 익히며 어떤 경우에, 어떤 상황에 어떤 아키텍터를 사용하는지 예제를 통해 살펴봅니다. 입문자들은 이러한 예제들을 2~3번 이상 살펴보는것은 권합니다. 그럼 이책을 읽고 다른책을 읽을때 보다 쉽게 이해할 수 있을것입니다.&lt;/p&gt;

&lt;h2 id=&quot;autoencoder-siamese-neural-network&quot;&gt;Autoencoder, Siamese Neural Network&lt;/h2&gt;
&lt;p&gt;생성모델이나, 얼굴인식같은 예제를 위해 오토인코더나 샴 네트워크를 살펴봅니다. 신경망에서 굉장히 중요한 역활을 하고 있고 현업에서도 아주 많이 사용될 수 있는 신경망 아키텍처입니다. 다른 아키텍처와 같이 모두 케라스로 구현하며 학습하고 실제 실행결과를 확인할 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;word-embedding-one-shot-learning&quot;&gt;Word-Embedding, One-shot Learning&lt;/h2&gt;
&lt;p&gt;신경망을 공부하기 위해 신경망에 데이터를 어떻게 주입할지, 상황에 따라 한두장의 데이터를 학습하여 모델을 어떻게 실행하는지에 대한 예제를 살펴볼수 있습니다. 굉장히 중요한 기법들이며 이렇게 얇은 책으로 이러한 내용을 공부할 수 있어서 입문자들에게 정말 좋을 것 같습니다!&lt;/p&gt;

&lt;h2 id=&quot;마무리&quot;&gt;마무리&lt;/h2&gt;
&lt;p&gt;신경망은 딥러닝의 기초가 되는 알고리즘이라고 할 수 있습니다. 이책도 제목은 신경망교과서이지만 사실 딥러닝이 대부분이라고 할 수 있습니다. 이번에 좋은 기회를 통해 신경망 교과서를 리뷰하면서 몇 년전만해도 신경망을 익힐려면 정말 어려운 책들을 통해 시작할 수 밖에 없었는데 이제는 입문자들이 본 책을 통해 보다 쉽게 입문할 수 있을거라는 생각이 들었습니다. 여러번 봐도 시간이 아깝지 않을 책이고 케라스를 사용해 딥러닝을 구현하는데 있어 기본기를 익힐수 있는 좋은 도서라고 생각합니다.&lt;/p&gt;</content><author><name>Youngwon Seo</name></author><summary type="html">본 글은 이번에 길벗에서 출간(번역)한 신경망 교과서에 대한 리뷰글입니다.</summary></entry><entry><title type="html">An Algorithm Based on Deep Learning for Predicting In-Hospital Cardiac Arrest</title><link href="http://youngwonseo.github.io/2020/06/22/vuno-01/" rel="alternate" type="text/html" title="An Algorithm Based on Deep Learning for Predicting In-Hospital Cardiac Arrest" /><published>2020-06-22T00:00:00+09:00</published><updated>2020-06-22T00:00:00+09:00</updated><id>http://youngwonseo.github.io/2020/06/22/vuno-01</id><content type="html" xml:base="http://youngwonseo.github.io/2020/06/22/vuno-01/">&lt;h2 id=&quot;논문링크&quot;&gt;논문링크&lt;/h2&gt;
&lt;p&gt;https://www.researchgate.net/publication/325998266_An_Algorithm_Based_on_Deep_Learning_for_Predicting_In-Hospital_Cardiac_Arrest/fulltext/5b6221aaa6fdccf0b206c3d4/An-Algorithm-Based-on-Deep-Learning-for-Predicting-In-Hospital-Cardiac-Arrest.pdf?origin=publication_detail&lt;/p&gt;

&lt;h2 id=&quot;absract&quot;&gt;Absract&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;4개의 vital sign을 사용해 심정지와 사망에 대한 위험도를 예측
    &lt;ul&gt;
      &lt;li&gt;systolic blood pressure&lt;/li&gt;
      &lt;li&gt;heart rate&lt;/li&gt;
      &lt;li&gt;respiratory rate&lt;/li&gt;
      &lt;li&gt;body temperature&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;2010.06 ~ 2017.07에 수집한 52,131명의 환자 데이터를 사용
    &lt;ul&gt;
      &lt;li&gt;2010.06~2017.01 학습 데이터로 사용&lt;/li&gt;
      &lt;li&gt;2017.02~2017.07 테스트 데이터로 사용&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;순환신경망을 사용
    &lt;ul&gt;
      &lt;li&gt;순환신경망 기반의 LSTM을 사용&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;기존의 방법보다 높은 sensitivity와 낮은 false-alarm을 보임
    &lt;ul&gt;
      &lt;li&gt;sensitivity - event가 발생했다고 예측하는 것 중 실제 event가 발생한 비율&lt;/li&gt;
      &lt;li&gt;결국 sensitivity가 높다는것은 낮은 false-alarm을 의미&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;80%의 심정지 환자는 악화증상을 심정지 8시간 전에 보임&lt;/li&gt;
  &lt;li&gt;생존율이 20%이하를 보임(미국 기준)&lt;/li&gt;
  &lt;li&gt;심정지를 예측하기 위해 TTS(track-and-trigger system)기반의 RRS(Rapid response system) 사용 됨
    &lt;ul&gt;
      &lt;li&gt;각 vital sign 수치의 임계값(upper, under)을 기반으로 검사&lt;/li&gt;
      &lt;li&gt;각 vital sign에 가중치를 사용해 계산후 합계를 기반으로 score를 계산&lt;/li&gt;
      &lt;li&gt;정해진 가중치 값들을 이용해 계산한 결과를 MEWS(the modified early warning score)라고 함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;많은 이전 연구들은 sensitivity을 개선하는것에 초점을 둠
    &lt;ul&gt;
      &lt;li&gt;false-alarm에 대한 의료진의 시간낭비, 운영 비용증가&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;본 연구에서는 DEWS(deep learning based early warning system)을 제안
    &lt;ul&gt;
      &lt;li&gt;높은 sensitivity와 낮은 false-alarm의 성능&lt;/li&gt;
      &lt;li&gt;vital sign과 심정지의 관계를 deep learning으로 학습&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;deep-learning-model-for-early-warning-system&quot;&gt;Deep learning model for early warning system&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/public/vuno01.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;
&lt;h3 id=&quot;study-flow-chart&quot;&gt;Study flow chart&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/public/vuno02.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;accuracy&quot;&gt;Accuracy&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/public/vuno03.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;</content><author><name>Youngwon Seo</name></author><summary type="html">논문링크 https://www.researchgate.net/publication/325998266_An_Algorithm_Based_on_Deep_Learning_for_Predicting_In-Hospital_Cardiac_Arrest/fulltext/5b6221aaa6fdccf0b206c3d4/An-Algorithm-Based-on-Deep-Learning-for-Predicting-In-Hospital-Cardiac-Arrest.pdf?origin=publication_detail</summary></entry><entry><title type="html">AI for Medical Treatment - week2</title><link href="http://youngwonseo.github.io/2020/06/20/03-week2/" rel="alternate" type="text/html" title="AI for Medical Treatment - week2" /><published>2020-06-20T00:00:00+09:00</published><updated>2020-06-20T00:00:00+09:00</updated><id>http://youngwonseo.github.io/2020/06/20/03-week2</id><content type="html" xml:base="http://youngwonseo.github.io/2020/06/20/03-week2/">&lt;h2 id=&quot;학습할-내용&quot;&gt;학습할 내용&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Medical Question Answering&lt;/li&gt;
  &lt;li&gt;BERT (자연어처리 모델)&lt;/li&gt;
  &lt;li&gt;label extraction&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;question-answering&quot;&gt;Question Answering&lt;/h2&gt;
&lt;h3 id=&quot;medical-question-answering&quot;&gt;Medical question answering&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/public/medicine/03/02/01.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;검색엔진을 통해 답이 포함된 구절을 찾을 수 있음&lt;/li&gt;
  &lt;li&gt;검색의 결과 구절에서 답변에 대한 짦은 문장을 찾아내는 것이 핵심&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/02/02.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;위 모델은 입력으로 질문에 해당하는 Q와 검색엔진의 결과(답이 포함되어 있음)인 P를 통해, P에 포함된 답변 A를 출력하는 모델&lt;/li&gt;
  &lt;li&gt;최근 ELMo, BERT, XLNet 등의 QA시스템 자연어 처리 모델이 존재&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/02/03.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;위 그림은 BERT에 대한 그림&lt;/li&gt;
  &lt;li&gt;여러개의 transformer block으로 구성&lt;/li&gt;
  &lt;li&gt;이전 그림에서와 같이 Q와 P를 입력으로함&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/02/04.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;입력에 대한 Q와 P는 토크나이징되어 seperator에 대한 구문을 사이에 두고 결합된 형태&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/02/05.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;토큰은 transformer block을 통과해 768-dimensional의 백터로 변환&lt;/li&gt;
  &lt;li&gt;이를 word representaion이라함&lt;/li&gt;
  &lt;li&gt;768차원의 공간에서 비슷한 단어끼리는 비슷한 위치에 존재함&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;handling-words-with-multiple-meanings&quot;&gt;Handling words with multiple meanings&lt;/h3&gt;

&lt;h3 id=&quot;define-the-answer-in-a-text&quot;&gt;Define the answer in a text&lt;/h3&gt;

&lt;p&gt;Non-Contextualized Word Representations&lt;/p&gt;

&lt;p&gt;Contextualized Work Representations&lt;/p&gt;

&lt;p&gt;BioBERT&lt;/p&gt;

&lt;h2 id=&quot;automatic-labeling&quot;&gt;Automatic Labeling&lt;/h2&gt;

&lt;p&gt;Automatic label extraction for medical imaging&lt;/p&gt;

&lt;h2 id=&quot;evalute-automatic-labeling&quot;&gt;Evalute Automatic Labeling&lt;/h2&gt;</content><author><name>Youngwon Seo</name></author><summary type="html">학습할 내용 Medical Question Answering BERT (자연어처리 모델) label extraction</summary></entry><entry><title type="html">AI for Medical Treatment - week1</title><link href="http://youngwonseo.github.io/2020/06/04/03-week1/" rel="alternate" type="text/html" title="AI for Medical Treatment - week1" /><published>2020-06-04T00:00:00+09:00</published><updated>2020-06-04T00:00:00+09:00</updated><id>http://youngwonseo.github.io/2020/06/04/03-week1</id><content type="html" xml:base="http://youngwonseo.github.io/2020/06/04/03-week1/">&lt;p&gt;Contents of third course of specialization&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;week1
    &lt;ul&gt;
      &lt;li&gt;how to build any valid models for SVT treatment effects.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;week2
    &lt;ul&gt;
      &lt;li&gt;question-answering application using BERT.&lt;/li&gt;
      &lt;li&gt;how to automatically have a machine read radiology reports and extract the mentions of diseases from those reports(get to that lable data from unstructured text in radiology reports).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;week3
    &lt;ul&gt;
      &lt;li&gt;how to interpret machine learning models.&lt;/li&gt;
      &lt;li&gt;look at techniques that make use of all of that unstructured data.&lt;/li&gt;
      &lt;li&gt;methods that can use to determind how different features are contributing to a model’s decision.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;randomized-control-trials&quot;&gt;Randomized Control Trials&lt;/h2&gt;

&lt;h3 id=&quot;absolute-risk-reduction-arr&quot;&gt;Absolute Risk Reduction (ARR)&lt;/h3&gt;
&lt;p&gt;treatment
control&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/01/03-01.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;각그룹에서 heart attack이 2%, 5%로 발생&lt;/li&gt;
  &lt;li&gt;treatment effect가 0.02 absolute rick(AR)과 0.05AR&lt;/li&gt;
  &lt;li&gt;0.03 absolute risk reduction (ARR)로 표현가능
    &lt;ul&gt;
      &lt;li&gt;control그룹의 AR - treatment그룹의 AR&lt;/li&gt;
      &lt;li&gt;0.05 - 0.02 = 0.03&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;randomized-control-trials-rct&quot;&gt;Randomized Control Trials (RCT)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;absolute risk reduction은 알게 되었지만 treatment그룹과 control그룹에 지정된 환자의 나이 및 건강상태도 중요함&lt;/li&gt;
  &lt;li&gt;예로들어 treatment그룹이 대부분 젊고 건강상태가 양호한 환자들로 구성되어있다면 treatment그룹의 heart attack에 대한 AR가 현저히 낮게 측정된 것임&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/01/03-02.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;각 그룹의 평균, 표준편차 등의 특성을 이용해 두 그룹이 비슷하다는것을 보일수 있음&lt;/li&gt;
  &lt;li&gt;ARR이 0.03이고 p-value가 0.001일 경우 치료가 실제로 효과를 발휘할 경우 0.03 이상의 위험 차이를 관찰 할 확률은 0.1 % 미만입니다.&lt;/li&gt;
  &lt;li&gt;p-value는 낮을수록 효과가&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;average-treatment-effect&quot;&gt;Average Treatment Effect&lt;/h2&gt;
&lt;h3 id=&quot;causal-inference&quot;&gt;Causal inference&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;treatment 유무에 대한 결과(outcome)에 따라 적용여부를 판단
    &lt;ul&gt;
      &lt;li&gt;treatment 적용으로 인해 heart attack과 같은 risk가 감소하면 treatment를 적용&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/01/03-03.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;위 표 처럼 환자에 따라 treatment 유무에 따른 결과를 기반으로 Benefit/No effect/Harm 으로 구분&lt;/li&gt;
  &lt;li&gt;위 표는 아래의 표와 같이 표현가능&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/01/03-04.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Y(1) 은 treatment적용, Y(0)은 treatment 미적용을 의미&lt;/li&gt;
  &lt;li&gt;이것을 Neyman-Rubin causal model이라 함&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/01/03-05.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Y(1) - Y(0) 의 평균을 Average Treatment Effect라 함&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;average-treatment-effect-1&quot;&gt;Average treatment effect&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;현실에서는 treatment 유무에 대한 결과를 얻을수 없음&lt;/li&gt;
  &lt;li&gt;이를 fundamental problem of causal inference라 함&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/01/03-06.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;현실에서는 위와 같이 treatment의 유 또는 무에 대한 결과만 관찰가능&lt;/li&gt;
  &lt;li&gt;실제 적용여부에 대한 결과를 observed/factual 이라하고 미적용의 알수없는 결과를 unobserved/conuterfactual이라함&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/01/03-07.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;W는 treatment 적용 여부&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/01/03-08.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;treatment 적용여부(W)에 따라 평균을 계산&lt;/li&gt;
  &lt;li&gt;randomized controlled trials 안에서&lt;/li&gt;
  &lt;li&gt;0.32 - 0.51 = -0.19
    &lt;ul&gt;
      &lt;li&gt;average risk reduction (ARR) = 0.19 (19%)&lt;/li&gt;
      &lt;li&gt;average treatment effect (ATE)= -0.19&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;conditional-average-treatment-effect&quot;&gt;Conditional average treatment effect&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;이전에 ATE를 계산함으로써 평균적인 effect를 구할수 있었음&lt;/li&gt;
  &lt;li&gt;그럼 좀더 개별적인 treatment의 effect를 구하려면 어떻게 해야할까?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/01/03-09.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;나이가 56세인 환자에 대한 effect를 계산하기 위해 같은 나이의 환자에 대한 ATE를 계산&lt;/li&gt;
  &lt;li&gt;이처럼 환자의 특정 feature값에 대응되는 effect결과를 Conditional aveage treatment effect(CATE)라 함&lt;/li&gt;
  &lt;li&gt;하지만 위처럼 매우 적은 샘플의 수로 계산할 경우, 또는 데이터가 한쪽(treatment에 대해)만 존재하는 경우 데이터의 편향을 따름&lt;/li&gt;
  &lt;li&gt;이런 경우 환자가 가지고 있는 각 feature간의 관계를 통해 estimate를 얻을 수 있음&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/01/03-10.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;x는 condition을 의미
    &lt;ul&gt;
      &lt;li&gt;age가 56인 경우 x = [56]&lt;/li&gt;
      &lt;li&gt;age가 56, BP가 130인 경우 x = [56,130]&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;각 조건에 대해 treatment에 따라 treatment response function과 control response function으로 구분&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;t-learner&quot;&gt;T-Learner&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/public/medicine/03/01/03-11.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;treatment response function(μ1)과 control reonse function(μ0)은 base learner를 통해 학습가능&lt;/li&gt;
  &lt;li&gt;age, bp가 인풋에 해당하고 y가 아웃풋에 해당&lt;/li&gt;
  &lt;li&gt;training data와 validation data로 학습&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/01/03-12.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;base learner로 decision tree를 선택한 경우는 다음과 같음&lt;/li&gt;
  &lt;li&gt;age=56, BP=130인 환자에 대한 risk를 계산
    &lt;ul&gt;
      &lt;li&gt;각 feature에 대한 위험도를 의미하는 노드로 결과를 계산&lt;/li&gt;
      &lt;li&gt;μ1에 대한 트리의 노드(age 56에 해당)를 통해 risk score를 0.21으로 판단&lt;/li&gt;
      &lt;li&gt;μ0에 대한 트리의 노드(BP 130에 해당)를 통해 risk score를 0.45로 판단&lt;/li&gt;
      &lt;li&gt;μ1 - μ0 = -0.24&lt;/li&gt;
      &lt;li&gt;이를 Two-Tree method 또는 T-learner라고 함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;s-learner&quot;&gt;S-Learner&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;하나의 모델로 treatment가 1인 경우와 0인경우의 risk를 계산하는것을 Single-Tree method 또는 S-learner라고 함
&lt;img src=&quot;/public/medicine/03/01/03-13.PNG&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;/public/medicine/03/01/03-14.PNG&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;age=56, BP=130인 환자에 대한 risk를 계산
    &lt;ul&gt;
      &lt;li&gt;각 feature에 대한 값과 teatment 여부에 대한 판단을 하나의 모델을 통해 계산&lt;/li&gt;
      &lt;li&gt;0.40 - 0.50 = -0.10&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;모델에 treatment 여부에 따른 노드가 없을 경우 s1-s0=0, s1과 s0은 같은 값이 됨&lt;/li&gt;
  &lt;li&gt;T-Learner의 경우 각 모델이 전체 데이터의 반씩 할당되어 학습되기 때문에 학습을 위해 보다 적은 데이터로 밖에 학습시킬수 없음&lt;/li&gt;
  &lt;li&gt;T-Learner와 S-Learner는 covariates를 사용한 risk를 예측하는 간단한 방법의 일부&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;individualized-treatment-effect&quot;&gt;Individualized Treatment Effect&lt;/h2&gt;
&lt;h3 id=&quot;evaluate-individualized-treatment-effect&quot;&gt;Evaluate individualized treatment effect&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/public/medicine/03/01/03-15.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;W=1이므로 Y(1)인 treatment 적용일 경우 0의 결과를 보임&lt;/li&gt;
  &lt;li&gt;이때 Y(0)은 어떻게 구할것인가?&lt;/li&gt;
  &lt;li&gt;여기에는 두가지 방법이 있는데 비슷한 feature를 가진 환자의 Y(0)를 구하거나 비슷한 ITE 를 가진 환자의 Y(0)을 계산하는것&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/01/03-16.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Matched Pair란 W가 서로 다른 두 쌍을 의미함&lt;/li&gt;
  &lt;li&gt;ITE estimate의 평균을 사용&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/01/03-17.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;각 pair에 대한 Y(1) - Y(0)의 결과에 의해 Harm/Benefit/No Effect를 판단&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;c-for-benefit&quot;&gt;C-for-benefit&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;각 pair의 결과를 사용해 C-for-benefit을 계산(C-Index와 유사)&lt;/li&gt;
  &lt;li&gt;각 pair에 대한 estimate와 outcome을 비교해 다음과 같이 판단
    &lt;ul&gt;
      &lt;li&gt;Concordant Pair : estimate와 outcome가 한쪽이 더 높은 경우&lt;/li&gt;
      &lt;li&gt;Concordant Pair : estimate가 높은 쪽이 outcome은 낮은 경우&lt;/li&gt;
      &lt;li&gt;Risk Tie : estimate와 outcome이 동인한 경우&lt;/li&gt;
      &lt;li&gt;Tie in Outcome : outcome은 동인한ㄷ네 estimate가 다른경우&lt;/li&gt;
      &lt;li&gt;Permissible : outcome이 서로 다른 경우&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/03-18.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;c-for-benefit-calculation&quot;&gt;C-for-benefit calculation&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/01/03-19.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;위와 같은 pair들이 존재할때 C-index를 계산하면 다음과 같음
    &lt;ul&gt;
      &lt;li&gt;Permissible Pairs에 속하는, 즉 outcome이 다른 pair는 AB, AC, AD, BC, BD (C와 D는 outcome이 같아서 아님)&lt;/li&gt;
      &lt;li&gt;Concordant Pairs에 속하는, 즉 한쪽으로만 estimate와 outcome이 높은경우는 AB, AC, BC, BD&lt;/li&gt;
      &lt;li&gt;Risk Ties에 속하는것, 즉 estimate와 outcome이 같은 경우는 없음&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/01/03-20.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;C-for-benefit을 계산하기 위해 주어진 데이터로 부터 먼저 C-index를 계산
    &lt;ol&gt;
      &lt;li&gt;W가 0, 1 즉 treatment여부에 따라 데이터를 분리(위 두개의 테이블)&lt;/li&gt;
      &lt;li&gt;각 테이블을 ITE를 기반으로 정렬(오름차순)&lt;/li&gt;
      &lt;li&gt;위에서 부터 각 순으로 Pair가 됨(YD는 Y의 차이, TE는 ITE의 평균)&lt;/li&gt;
      &lt;li&gt;YD는 outcome을 의미하고 TE는 estimate를 의미&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/03/01/03-21.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;C-for-benefit의 의미
    &lt;ul&gt;
      &lt;li&gt;2개의 랜덤한 A,B pair에 대하여 A의 outcome과 estimate가 더 높으면 60%의 확률로 A가 더 치료가 잘될것으로 예측된다는것&lt;/li&gt;
      &lt;li&gt;60%이라는 값은 S-Learner를 의미&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;assignment&quot;&gt;Assignment&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;How to analyze data from a randomized control trial using both:
    &lt;ul&gt;
      &lt;li&gt;traditional statistical methods&lt;/li&gt;
      &lt;li&gt;and the more recent machine learning techniques&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Interpreting Multivariate Models
    &lt;ul&gt;
      &lt;li&gt;Quantifying treatment effect&lt;/li&gt;
      &lt;li&gt;Calculating baseline risk&lt;/li&gt;
      &lt;li&gt;Calculating predicted risk reduction&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Evaluating Treatment Effect Models
    &lt;ul&gt;
      &lt;li&gt;Comparing predicted and empirical risk reductions&lt;/li&gt;
      &lt;li&gt;Computing C-statistic-for-benefit&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Interpreting ML models for Treatment Effect Estimation
    &lt;ul&gt;
      &lt;li&gt;Implement T-learner&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Youngwon Seo</name></author><summary type="html">Contents of third course of specialization</summary></entry><entry><title type="html">금융데이터 활용하기</title><link href="http://youngwonseo.github.io/2020/05/30/memo/" rel="alternate" type="text/html" title="금융데이터 활용하기" /><published>2020-05-30T00:00:00+09:00</published><updated>2020-05-30T00:00:00+09:00</updated><id>http://youngwonseo.github.io/2020/05/30/memo</id><content type="html" xml:base="http://youngwonseo.github.io/2020/05/30/memo/">&lt;h2 id=&quot;1-데이터-수집&quot;&gt;1. 데이터 수집&lt;/h2&gt;

&lt;h3 id=&quot;해외-pandas-datareader&quot;&gt;해외 (pandas-datareader)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;해외주가 - tiingo&lt;/li&gt;
  &lt;li&gt;주가 지수(코스피, 나스닥 등) - Stooq&lt;/li&gt;
  &lt;li&gt;환율 - Alpha Vanatage&lt;/li&gt;
  &lt;li&gt;원자재 가격 - FRED&lt;/li&gt;
  &lt;li&gt;그 외 경제지표
    &lt;ul&gt;
      &lt;li&gt;90개 이상 공식적 통계 기관 경제 데이터 - Econdb&lt;/li&gt;
      &lt;li&gt;세인트루이스 연방준비은행에서 제공하는 주요 경제 지표 - Fred&lt;/li&gt;
      &lt;li&gt;세계 은행에서 제공하는 경제 지표 - World Bank&lt;/li&gt;
      &lt;li&gt;OECD 국가 통계 자료 - OECD&lt;/li&gt;
      &lt;li&gt;Enigma&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;국내-finance-datareader&quot;&gt;국내 (finance-datareader)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;pip install finance-datareader&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;open-api&quot;&gt;OPEN API&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;국가 재정&lt;/li&gt;
  &lt;li&gt;인구/가구&lt;/li&gt;
  &lt;li&gt;경기/기업 경영&lt;/li&gt;
  &lt;li&gt;국토 관리&lt;/li&gt;
  &lt;li&gt;물가/가계&lt;/li&gt;
  &lt;li&gt;금리/환율&lt;/li&gt;
  &lt;li&gt;주식/채권&lt;/li&gt;
  &lt;li&gt;무역/국제 수지&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;크롤링&quot;&gt;크롤링&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;urlopen, BeautifulSoup&lt;/li&gt;
  &lt;li&gt;requests&lt;/li&gt;
  &lt;li&gt;기업재무정보 - http://comp.fnguide.com/&lt;/li&gt;
  &lt;li&gt;pip install selenium&lt;/li&gt;
  &lt;li&gt;증권 정보 포털 - SEIBro
    &lt;ul&gt;
      &lt;li&gt;법인만 API제공&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;실제-데이터-수집&quot;&gt;실제 데이터 수집&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;scrapy 프로젝트를 생성하여 수집&lt;/li&gt;
  &lt;li&gt;주요 경제 지표 수집하기
    &lt;ul&gt;
      &lt;li&gt;한국은행 OpenAPI - https://ecos.or.kr&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;주가 정보 수집하기
    &lt;ul&gt;
      &lt;li&gt;FinanceDataReader 사용&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;재무재표 데이터 수집하기
    &lt;ul&gt;
      &lt;li&gt;OPEN DART - opendart.fss.or.kr&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-금융-데이터-분석하기&quot;&gt;2. 금융 데이터 분석하기&lt;/h2&gt;

&lt;h3 id=&quot;데이터-정리하기&quot;&gt;데이터 정리하기&lt;/h3&gt;

&lt;h3 id=&quot;데이터-시각화-및-분석하기&quot;&gt;데이터 시각화 및 분석하기&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;matplotlib&lt;/li&gt;
  &lt;li&gt;seaborn&lt;/li&gt;
  &lt;li&gt;tip, interactc
    &lt;ul&gt;
      &lt;li&gt;jupyter notebook interaction&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;데이터-프레젠테이션하기&quot;&gt;데이터 프레젠테이션하기&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;flask, dash를 사용한 대시보드 만들기
    &lt;ul&gt;
      &lt;li&gt;https://dash.plotly.com&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-금융-데이터-활용하기&quot;&gt;3. 금융 데이터 활용하기&lt;/h2&gt;

&lt;h3 id=&quot;인구-통계&quot;&gt;인구 통계&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;국가통계포털 : http://kosis.kr&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;유동성과-주가-부동산-가격-비교하기&quot;&gt;유동성과 주가, 부동산 가격 비교하기&lt;/h3&gt;

&lt;h3 id=&quot;주요-각국의-기준-금리-비교하기&quot;&gt;주요 각국의 기준 금리 비교하기&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;https://global-rates.com&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;금융-대시보드-만들기&quot;&gt;금융 대시보드 만들기&lt;/h3&gt;

&lt;h3 id=&quot;매매가-대비-전세가-높은-아파트-찾아보기&quot;&gt;매매가 대비 전세가 높은 아파트 찾아보기&lt;/h3&gt;

&lt;h3 id=&quot;강남역에서-가까운-아파트-찾아보기&quot;&gt;강남역에서 가까운 아파트 찾아보기&lt;/h3&gt;

&lt;h3 id=&quot;배당-수익률이-높은-주식-찾아보기&quot;&gt;배당 수익률이 높은 주식 찾아보기&lt;/h3&gt;

&lt;h3 id=&quot;퀀트-투자-따라-하기&quot;&gt;퀀트 투자 따라 하기&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;zipline
    &lt;ul&gt;
      &lt;li&gt;quandl.com&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;미국 주식 투자 백 테스트&lt;/li&gt;
  &lt;li&gt;한국 주식 투자 백 테스트&lt;/li&gt;
  &lt;li&gt;볼린저 밴드를 이용한 투자 방법 평가하기&lt;/li&gt;
  &lt;li&gt;pyfolio로 투자 방법 비교하기&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;refereces&quot;&gt;Refereces&lt;/h1&gt;</content><author><name>Youngwon Seo</name></author><summary type="html">1. 데이터 수집</summary></entry><entry><title type="html">XAI #4 - 의사 결정 트리</title><link href="http://youngwonseo.github.io/2020/05/16/04-decision-tree/" rel="alternate" type="text/html" title="XAI #4 - 의사 결정 트리" /><published>2020-05-16T00:00:00+09:00</published><updated>2020-05-16T00:00:00+09:00</updated><id>http://youngwonseo.github.io/2020/05/16/04-decision-tree</id><content type="html" xml:base="http://youngwonseo.github.io/2020/05/16/04-decision-tree/">&lt;p&gt;본 글은 &lt;a href=&quot;https://wikibook.co.kr/xai/&quot; target=&quot;_blank&quot;&gt;XAI 설명가능한 인공지능, 인공지능을 해부하다, (안재현 지금, 위키북스)&lt;/a&gt;의 &lt;strong&gt;4장 의사 결정 트리&lt;/strong&gt; 내용을 요약한 것입니다.&lt;/p&gt;

&lt;h2 id=&quot;의사결정트리&quot;&gt;의사결정트리&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;의사결정트리는 질의과정이 트리형태(브런치로 분기가되는)로 나타나는 분류(classification) 또는 예측(prediction)을 위한 분석방법(지도학습)&lt;/li&gt;
  &lt;li&gt;답을 찾아가는 과정을 도식적으로 표현가능하여 연구자가 분석 과정을 쉽게 이해하고 설명할 수 있다는 장점이 있음&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;일반적으로 의사결정 트리는 정보 이득 수치를 계산해 최적 목표를 달성, 즉 주어진 데이터를 잘 설명하는 트리를 만들기 위해 정보 이득을 이용하는데 이것은 엔트로피 변화량을 의미
&lt;img src=&quot;엔트로피 수식&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;정보 이득, 즉 엔트로피량이 커지면 획득할 정보 이득의 양이 커진다는 것을 의미&lt;/li&gt;
  &lt;li&gt;의사결정트리는 다양한 분류방식을 시도하고 정보 이득량이 가장 커지는 방향으로 트리를 학습, 이를 재귀적 분기(recursive partitioning) 하고 함&lt;/li&gt;
  &lt;li&gt;모든 학습 데이터에 대해 100% 분류가되는 트리를 풀 트리(full tree)라고 함, 이는 과적합(overffiting)의 가능성이 있음&lt;/li&gt;
  &lt;li&gt;이를 방지하기 위해 특정 임계값보다 낮은 수준의 정보 이득을 발생시키는 가지를 잘라냄, 이를 프루닝(prunning)이라 함&lt;/li&gt;
  &lt;li&gt;의사결정트리에 대한 자세한 설명은 위키피디아나 다른 머신러닝 서적 참고 필요&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;의사-결정-트리-시각화&quot;&gt;의사 결정 트리 시각화&lt;/h2&gt;

&lt;h2 id=&quot;피처-중요도-구하기&quot;&gt;피처 중요도 구하기&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;피처 중요도(feature importance, 또는 퍼뮤테이션 중요도[permutation importance])는 데이터의 피처가 알고리즘의 정확한 분류에 얼마나 큰 영향을 미치는지, 즉 피처가 알고리즘을 학습하는데 있어서 얼마나 중요한지 분석하는 기법&lt;/li&gt;
  &lt;li&gt;특정 피처값을 임의의 값으로 변경했을때 에러가 얼마나 증가하는지 측정, 만약 에러가 크게 증가하는 경우 해당 알고리즘은 변경한 피처에 의존하여 결정을 하는것으로 판단 가능&lt;/li&gt;
  &lt;li&gt;만약 피처의 값을 변경했는데 모델 성능이 변화가 없다면 그 피처는 무시 가능&lt;/li&gt;
  &lt;li&gt;이러한 피처 중요도를 계산하는 한 가지 방법인 피셔, 루딘, 도미니치의 피터 중요도 계산 방법
    &lt;ol&gt;
      &lt;li&gt;주어진 모델의 에러를 측정&lt;/li&gt;
      &lt;li&gt;X의 피처 k개에 대하여
        &lt;ol&gt;
          &lt;li&gt;피처 매트릭스 X를 계산, X는 각 피처를 임의의 값으로 변경한 모델&lt;/li&gt;
          &lt;li&gt;X의 모델 에러를 측정, 변경된 피처값을 사용하여 에러측정&lt;/li&gt;
          &lt;li&gt;퍼뮤테이션 피처 중요도를 산정, 각 k의 F1 = permutation error / origin error&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;피처의 중요도 F1을 계산&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;xgboost&quot;&gt;XGBoost&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;XGBoost(eXtreme Gradient Boosting)는 캐글에서 다수의 우승을 한 의사결정트리로 사용하기 쉽고 CPU만으로도 학습가능한 알고리즘&lt;/li&gt;
  &lt;li&gt;배깅(Bagging), 부스팅(Boostring), 스태킹(Stacking)을 활용&lt;/li&gt;
  &lt;li&gt;XGBoost는 딥러닝은 아님&lt;/li&gt;
  &lt;li&gt;피처가 많지 않다면&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;기본-원리&quot;&gt;기본 원리&lt;/h3&gt;

&lt;h3 id=&quot;파라미터&quot;&gt;파라미터&lt;/h3&gt;

&lt;p&gt;https://gist.github.com/ktisha/c21e73a1bd1700294ef790c56c8aec1f&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Number of times pregnant&lt;/li&gt;
  &lt;li&gt;Plasma glucose concentration a 2 hours in an oral glucose tolerance test&lt;/li&gt;
  &lt;li&gt;Diastolic blood pressure (mm Hg)&lt;/li&gt;
  &lt;li&gt;Triceps skin fold thickness (mm)&lt;/li&gt;
  &lt;li&gt;2-Hour serum insulin (mu U/ml)&lt;/li&gt;
  &lt;li&gt;Body mass index (weight in kg/(height in m)^2)&lt;/li&gt;
  &lt;li&gt;Diabetes pedigree function&lt;/li&gt;
  &lt;li&gt;Age (years)&lt;/li&gt;
  &lt;li&gt;Class variable (0 or 1)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/public/xai/04/04_01.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;루트 노드를 살펴보면 f1이라고 명시되어 있는데 이것은 두 번째 피처인 혈장 포도당 농도를 의미, 즉 이 수치가 127.5 미만 또는 값이 없거나(missing) 그렇지 않을 경우를 기준으로 분기가 실행됨&lt;/li&gt;
  &lt;li&gt;그후 f7(나이) 또는 f5(BMI 수치)로 분기가 발생&lt;/li&gt;
  &lt;li&gt;leaf노드의 값은 로지스틱 함수 확률값(logistic function probability score)으로 0은 중립, 음수는 당뇨병 없음, 양수는 당뇨병이 있다고 분류한것을 의미(sigmoid(0.5) == 0), 즉 0.5를 임계값으로 당뇨병이 있다, 없다를 구분&lt;/li&gt;
  &lt;li&gt;XGBoost의 max_depth값을 조절하여 다음과 같이 프루닝된 트리 생성가능
&lt;img src=&quot;/public/xai/04/04_02.PNG&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;이처럼 의사결정트리를 시각화하면 모델이 어떤 피처를 우선순위로 생각하는지, 단계마다 어떤 기준으로 당뇨병을 진단하는지 순서대로 파악 가능&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;피처-중요도&quot;&gt;피처 중요도&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;피처들 간의 상관관계가 낮아야함, 즉 3개의 피처인 키, 몸무게, BMI는 키나 몸무게의 변화에 따라 변화하므로 피처 중요도가 높게 설정될 수 있음&lt;/li&gt;
  &lt;li&gt;피처 중요도는 피처 간 의존성이 낮은 상태에서 효율이 높음&lt;/li&gt;
  &lt;li&gt;다음은 피처 중요도를 출력하는 코드 및 결과&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;xgboost&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plot_importance&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'figure.figsize'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot_importance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/public/xai/04/04_03.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;결과는 중요도 준으로 정렬되어 있음&lt;/li&gt;
  &lt;li&gt;피처 중요도 순으로 꼭 의사결정트리의 순서가 결정되는 것은 아님, 트리는 정보 이득이 큰 방향으로 학습됨&lt;/li&gt;
  &lt;li&gt;그러나 대부분 피처 중요도와 의사결정트리의 순서가 동일함&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;부분-의존성-플롯&quot;&gt;부분 의존성 플롯&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/public/xai/04/04_04.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;다음은 데이터와 실제 모델을 결합해 두 결과가 일치하는지 확인하는 &lt;strong&gt;예측 분포 플롯(prediction distribution plot)&lt;/strong&gt;
&lt;img src=&quot;/public/xai/04/04_05.PNG&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;모델-튜닝&quot;&gt;모델 튜닝&lt;/h2&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://wikibook.co.kr/xai/&quot; target=&quot;_blank&quot;&gt;XAI 설명가능한 인공지능, 인공지능을 해부하다, (안재현 지금, 위키북스)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Youngwon Seo</name></author><summary type="html">본 글은 XAI 설명가능한 인공지능, 인공지능을 해부하다, (안재현 지금, 위키북스)의 4장 의사 결정 트리 내용을 요약한 것입니다.</summary></entry><entry><title type="html">XAI #5 - 대리 분석</title><link href="http://youngwonseo.github.io/2020/05/16/05-surroage-analysis/" rel="alternate" type="text/html" title="XAI #5 - 대리 분석" /><published>2020-05-16T00:00:00+09:00</published><updated>2020-05-16T00:00:00+09:00</updated><id>http://youngwonseo.github.io/2020/05/16/05-surroage-analysis</id><content type="html" xml:base="http://youngwonseo.github.io/2020/05/16/05-surroage-analysis/">&lt;p&gt;본 글은 &lt;a href=&quot;https://wikibook.co.kr/xai/&quot; target=&quot;_blank&quot;&gt;XAI 설명가능한 인공지능, 인공지능을 해부하다, (안재현 지금, 위키북스)&lt;/a&gt;의 &lt;strong&gt;5장 대리 분석&lt;/strong&gt; 내용을 요약한 것입니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;대리분석(surrogate analysis)은 본래 기능을 흉내 내는 간단한 대체재를 만들어 프로토타입이 동작하는지 판단하는 분석 방법&lt;/li&gt;
  &lt;li&gt;XAI에서는 모델이 너무 복잡해서 분석이 불가능 할때 유사한 기능을 수행하는 모델을 여러개 만들어 본래의 모델을 분석하는 방법을 의미&lt;/li&gt;
  &lt;li&gt;근사치 모델(approximation model), 반응 표기 기법(response surface model, RSM), 에뮬레이터(emulator)등으로 불림&lt;/li&gt;
  &lt;li&gt;원래 모델 f가 있고 흉내내는 모델 g가 존재 할 때, 다음 과 같은 조건에 부합되면 됨
    &lt;ol&gt;
      &lt;li&gt;g가 f보다 학습하기 쉽고&lt;/li&gt;
      &lt;li&gt;g는 설명가능한 모델&lt;/li&gt;
      &lt;li&gt;g는 f를 유사하게 흉내&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;학습데이터의 전부(또는 일부)를 사용한 대리분석 모델을 글로벌 대리 분석(global surrogate analysis)&lt;/li&gt;
  &lt;li&gt;학습데이터 하나를 해석하는 과정을 로컬 대리 분석(local surrogate analysis)&lt;/li&gt;
  &lt;li&gt;대리 분석의 가장 큰 장점은 &lt;strong&gt;모델 애그노스틱(model-agnostic technology, 모델에 대한 지식 없이도 학습가능)&lt;/strong&gt; 하다는 것&lt;/li&gt;
  &lt;li&gt;또한 적은 데이터로 설명가능한 모델을 만들수 있음&lt;/li&gt;
  &lt;li&gt;중간에 모델 f가 바뀌어도 피처만 같으면 대리 분석 수행 가능(모델들이 분리돼[decoupled] 있기 때문)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;글로벌-대리-분석&quot;&gt;글로벌 대리 분석&lt;/h3&gt;

&lt;h3 id=&quot;로컬-대리-분석&quot;&gt;로컬 대리 분석&lt;/h3&gt;

&lt;h2 id=&quot;lime&quot;&gt;LIME&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;LIME(local interpretable model-agnostic explanations)은 모델이 현재 데이터의 어떤 영역을 집중해서 분석했고 어떤 영역을 분류 근거로 사용했는지 알려주는 XAI기법&lt;/li&gt;
  &lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;실습-텍스트-데이터에-lime-적용하기&quot;&gt;실습: 텍스트 데이터에 LIME 적용하기&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;이번 실습에서는 20개의 카테고리로 구분되어 있는 뉴스기사를 분류하는 모델을 개발하고 LIME을 적용하는 예제를 구현&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 데이터 로드 및 전처리
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fetch_20newsgroups&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;newsgroups_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fetch_20newsgroups&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'train'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;newsgroups_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fetch_20newsgroups&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'test'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'misc'&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'.'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newsgroups_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'pc.hardware'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'mac.hardware'&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 모델 학습 및 성능 평가
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.metrics&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.naive_bayes&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MultinomialNB&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;vectorizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feature_extraction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TfidfVectorizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lowercase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_vectors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vectorizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newsgroups_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_vectors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vectorizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newsgroups_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;nb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MultinomialNB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;nb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_vectors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newsgroups_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_vectors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sklearn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newsgroups_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;average&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'weighted'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Youngwon Seo</name></author><summary type="html">본 글은 XAI 설명가능한 인공지능, 인공지능을 해부하다, (안재현 지금, 위키북스)의 5장 대리 분석 내용을 요약한 것입니다.</summary></entry><entry><title type="html">AI for Medical Diagnosis - Week3</title><link href="http://youngwonseo.github.io/2020/04/26/01-week3/" rel="alternate" type="text/html" title="AI for Medical Diagnosis - Week3" /><published>2020-04-26T00:00:00+09:00</published><updated>2020-04-26T00:00:00+09:00</updated><id>http://youngwonseo.github.io/2020/04/26/01-week3</id><content type="html" xml:base="http://youngwonseo.github.io/2020/04/26/01-week3/">&lt;p&gt;Image segmentation on MRI images&lt;/p&gt;

&lt;h2 id=&quot;key-concepts&quot;&gt;Key Concepts&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Perform image segmentation on 3D MRI data.&lt;/li&gt;
  &lt;li&gt;Take random sub-samples from a 3D image.&lt;/li&gt;
  &lt;li&gt;Standardize an input image.&lt;/li&gt;
  &lt;li&gt;Apply a pre-trained U-Net model.&lt;/li&gt;
  &lt;li&gt;Implement a proper loss function for model training (soft dice loss).&lt;/li&gt;
  &lt;li&gt;Evaluate model performance by calculating sensitivity and specificity.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Medical Image Segmentation
이미지에서 질병의 유무뿐만 아니라 질병이 발생한 위치를 탐지하는것&lt;/p&gt;

&lt;p&gt;MRI 데이터로 부터 종양을 segmentation&lt;/p&gt;

&lt;p&gt;MRI 데이터는 sequence로 구성됨 (axial view), 3D Volume을 구성&lt;/p&gt;

&lt;p&gt;여러개의 3D Volume으로 구성될 경우 각 데이터의 slice부분을 이용해 Multi Channels 데이터로 구성
3개 channel일 경우 RGB로 구성
ㅇ
데이터의 align인 맞지 않을 경우 registration을 통해 보정&lt;/p&gt;

&lt;p&gt;2D Approach는 3D MRI Volume을 2D slice로 분리, 각 2d에 대한 segmentation을 실행&lt;/p&gt;

&lt;p&gt;2D Approach는 3D context에서 발견가능한 중요한 사항들을 잃음, 예로들면 인접한 부분(depth)에 종양이 있음&lt;/p&gt;

&lt;p&gt;3D Approach는 한번에 모델에 입력이 불가능한 경우가 존재
3MRI Volume을  sub 3d MRI Volumn으로 분리 (width, height, depth)
그러나 이경우 지역적 context를 잃음&lt;/p&gt;

&lt;p&gt;U-Net은 biomedical image segmentaion을 위한 첫번째 모델&lt;/p&gt;

&lt;p&gt;100개 정도의 샘플만 가지고도 좋은 결과를 보임&lt;/p&gt;

&lt;p&gt;Contraction Path와 Expading Path로 구분됨
Contraction Path:  down sampling
Expading Path : up sampling&lt;/p&gt;

&lt;p&gt;https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/
https://towardsdatascience.com/u-net-b229b32b4a71
https://arxiv.org/pdf/1505.04597.pdf&lt;/p&gt;

&lt;p&gt;Data Augmentation&lt;/p&gt;

&lt;p&gt;roate 90 degree&lt;/p&gt;

&lt;p&gt;Soft Dice Loss&lt;/p&gt;

&lt;p&gt;Practical considerations&lt;/p&gt;

&lt;p&gt;일반화하기 어려움 - 나라별로 발생하는 질병이 다름, 
MRI기술은 표준화되어 있지 않음, 병원마다 MRI데이터의 스캔기술이 다름&lt;/p&gt;

&lt;p&gt;Extenal validation
distribution이 다른 데이터들에 대한 테스트&lt;/p&gt;

&lt;p&gt;Retrospective data와 real-world 데이터의 타이&lt;/p&gt;

&lt;p&gt;Model Interpretation&lt;/p&gt;

&lt;p&gt;Course3
환자에 도움이 되는가
설명가능한 모델&lt;/p&gt;</content><author><name>Youngwon Seo</name></author><summary type="html">Image segmentation on MRI images</summary></entry><entry><title type="html">AI for Medical Diagnosis - Week2</title><link href="http://youngwonseo.github.io/2020/04/25/01-week2/" rel="alternate" type="text/html" title="AI for Medical Diagnosis - Week2" /><published>2020-04-25T00:00:00+09:00</published><updated>2020-04-25T00:00:00+09:00</updated><id>http://youngwonseo.github.io/2020/04/25/01-week2</id><content type="html" xml:base="http://youngwonseo.github.io/2020/04/25/01-week2/">&lt;p&gt;Evaluating models&lt;/p&gt;

&lt;h2 id=&quot;2주차-key-concepts&quot;&gt;2주차 Key Concepts&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Calculate true positives, true negatives, false positives, false negatives.&lt;/li&gt;
  &lt;li&gt;Calculate sensitivity and specificity&lt;/li&gt;
  &lt;li&gt;Calculate Positive Predictive Value (PPV) and Negative Predictive Value (NPV).&lt;/li&gt;
  &lt;li&gt;Understand confidence intervals, ROC curve, and F1 score.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;의료 분야에서 진단에 대한 결정은 높은 영향력을 가집니다. 그래서 진단에 대한 딥러닝 모델을 개발시 모델에 대한 평가..&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;정확도 메트릭의 단점, sencitivity, specificity 정화도로 부터 의료 평가&lt;/li&gt;
  &lt;li&gt;의사들을 의사결정을 위한 예측 값&lt;/li&gt;
  &lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;다음은 정확도를 조건부 확률로 해석하는 과정입니다. +는 positive, 즉 질병(disease)으로 결정, -는 negative 질병이 아닌(normal)으로 결정을 의미합니다.
&lt;img src=&quot;/public/medicine/01/week2-03.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;Sensitivity : 질병일 경우 질병으로 예측할 확률, P(+&lt;/td&gt;
          &lt;td&gt;disease), (true positive rate)&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;Specificity : 질병이 아닐경우 질병이 아닌것으로 예측할 확률, P(-&lt;/td&gt;
          &lt;td&gt;normal), (true negative rate)&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/01/week2-04.png&quot; alt=&quot;&quot; /&gt;
Sensitivity와 Specificity를 사용해 정확도를 다시 표현해 봅니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Prevalence : 질병이 발병할 학률, P(disease)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;질병이 아닌 확률은 P(1-prevalence), P(1 - P(disease))입니다.&lt;/p&gt;

&lt;p&gt;이것은 정확도를 sensitivity와 specificity의 가중치 평균으로 ..&lt;/p&gt;

&lt;p&gt;예제를 살펴보겠습니다.
&lt;img src=&quot;/public/medicine/01/week2-05.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;Sensitivity : P(+&lt;/td&gt;
          &lt;td&gt;disease) = #(+ and disease) / #(disease) = 2/3 = 0.67&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;Specificity : P(-&lt;/td&gt;
          &lt;td&gt;normal) = #(- and normal) / #(normal) = 6/7 = 0.86&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;Prevalence : P(disease) = #(disease) / #(total) = 3/10 = 0.3&lt;/li&gt;
  &lt;li&gt;Accuracy : Sensitivity X prevalence + Specificity X (1 - prevalence) = 0.67 x 0.3 + 0.86 x 0.7 = 0.8&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;PPV(positive predictive value) : P(disease&lt;/td&gt;
      &lt;td&gt;+)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;NPV(nagative predictive value) : P(normal&lt;/td&gt;
      &lt;td&gt;-)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&quot;/public/medicine/01/week2-06.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Sensitivity, Specificity와 PPV, NPV의 관계를 Confusion matrix를 통해 알아니다.&lt;/p&gt;

&lt;p&gt;의료 모델에서 가장 유용한모델인 ROC curve에 대해 알아봅니다.&lt;/p&gt;

&lt;p&gt;이때 threshold가 0이면 sensitivity가 1,specificity 0&lt;/p&gt;

&lt;p&gt;threshold가 1이면 sensitivity가 0,specificity 1&lt;/p&gt;

&lt;p&gt;모델의 추정치에 대한 변동성
confidence intervals&lt;/p&gt;

&lt;p&gt;p는 population accuracy&lt;/p&gt;

&lt;p&gt;p에 대한 모델 학습은 불가능&lt;/p&gt;

&lt;p&gt;lower bound
upper bound&lt;/p&gt;

&lt;p&gt;confidence를 통해 confidence interval을 계산, population accuracy의 정확도를 유추
모델의 성능을 confidence intervals로 보고&lt;/p&gt;

&lt;p&gt;구간내에 있을 확률이 95% x
샘플 정확도의 95%가 구간내에 있을 확률  x&lt;/p&gt;

&lt;p&gt;Metrics&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;TP, TN, FP, FN&lt;/li&gt;
  &lt;li&gt;Accuracy&lt;/li&gt;
  &lt;li&gt;Prevalence&lt;/li&gt;
  &lt;li&gt;Sensitivity and Specificity&lt;/li&gt;
  &lt;li&gt;PPV and NPV&lt;/li&gt;
  &lt;li&gt;AUC
Confidence Intervals&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Youngwon Seo</name></author><summary type="html">Evaluating models</summary></entry></feed>